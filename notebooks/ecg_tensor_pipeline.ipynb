{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4798ea8d",
   "metadata": {},
   "source": [
    "# ECG Tensor Pipeline — Preprocessing, Training, Evaluation\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook provides an end-to-end pipeline for ECG signal classification:\n",
    "1. **Preprocessing**: Load raw ECG datasets, resample, normalize, and save per-record `.npz` files\n",
    "2. **Dataset & DataLoader**: Lazy loading with PyTorch for memory efficiency\n",
    "3. **Model**: Compact 1D CNN for ECG classification\n",
    "4. **Training**: GPU-accelerated training with mixed precision\n",
    "5. **Evaluation**: Metrics, confusion matrix, ROC curves, and visualizations\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Python 3.10+\n",
    "- Required packages: `numpy`, `scipy`, `pandas`, `wfdb`, `torch`, `scikit-learn`, `matplotlib`, `tqdm`, `nbformat`\n",
    "- Datasets should be in `Dataset/` folder\n",
    "- Unified label mapping CSV at `logs/unified_label_mapping.csv`\n",
    "\n",
    "## Running Headless\n",
    "\n",
    "To execute this notebook from the command line:\n",
    "\n",
    "```powershell\n",
    "jupyter nbconvert --to notebook --execute notebooks/ecg_tensor_pipeline.ipynb --output ecg_tensor_pipeline_executed.ipynb\n",
    "```\n",
    "\n",
    "**Note**: On Windows, if you see `RuntimeError: There is no current event loop in thread`, add this at the top of your script:\n",
    "\n",
    "```python\n",
    "import asyncio\n",
    "import sys\n",
    "if sys.platform == 'win32':\n",
    "    asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())\n",
    "```\n",
    "\n",
    "## GPU-Intensive Tasks\n",
    "\n",
    "The following cells will utilize GPU heavily when CUDA is available:\n",
    "- **Training loop**: Forward/backward passes, gradient updates\n",
    "- **Large batch evaluation**: Model inference on test set\n",
    "- **Mixed precision training**: Uses `torch.cuda.amp` for speedup\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "7de47890",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T13:26:48.791425Z",
     "start_time": "2025-12-01T13:26:47.771332Z"
    }
   },
   "source": [
    "# Environment checks, imports, seeds, and directory setup\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import json\n",
    "from pathlib import Path\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "from scipy.signal import resample\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, classification_report, \n",
    "    f1_score, precision_recall_fscore_support,\n",
    "    roc_curve, auc, precision_recall_curve\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Print environment info\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Check CUDA availability\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"\\nDevice: {DEVICE}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"Running on CPU - training will be slower\")\n",
    "\n",
    "# Set deterministic seeds for reproducibility\n",
    "DEFAULT_SEED = 42\n",
    "random.seed(DEFAULT_SEED)\n",
    "np.random.seed(DEFAULT_SEED)\n",
    "torch.manual_seed(DEFAULT_SEED)\n",
    "if DEVICE.type == 'cuda':\n",
    "    torch.cuda.manual_seed_all(DEFAULT_SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "print(f\"\\nRandom seed set to: {DEFAULT_SEED}\")\n",
    "\n",
    "# Define project paths\n",
    "# Try to detect if running inside notebooks/ or at project root\n",
    "CANDIDATES = [\n",
    "    Path.cwd().parent,                 # when running inside notebooks/\n",
    "    Path.cwd(),                        # when running at project root\n",
    "    Path(\"D:/ecg-research\").resolve()  # explicit fallback for this project\n",
    "]\n",
    "ROOT = next((p.resolve() for p in CANDIDATES if (p / \"Dataset\").exists()), Path.cwd().resolve())\n",
    "\n",
    "DATASET_DIR = ROOT / \"Dataset\"\n",
    "ARTIFACTS_DIR = ROOT / \"artifacts\"\n",
    "PROCESSED_DIR = ARTIFACTS_DIR / \"processed\"\n",
    "RECORDS_DIR = PROCESSED_DIR / \"records\"\n",
    "CHECKPOINTS_DIR = PROCESSED_DIR / \"checkpoints\"\n",
    "FIGURES_DIR = ARTIFACTS_DIR / \"figures\"\n",
    "LOGS_DIR = ROOT / \"logs\"\n",
    "\n",
    "# Create directories\n",
    "for p in [ARTIFACTS_DIR, PROCESSED_DIR, RECORDS_DIR, CHECKPOINTS_DIR, FIGURES_DIR, LOGS_DIR]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"\\nProject Paths:\")\n",
    "print(f\"  ROOT: {ROOT}\")\n",
    "print(f\"  DATASET_DIR: {DATASET_DIR} (exists: {DATASET_DIR.exists()})\")\n",
    "print(f\"  PROCESSED_DIR: {PROCESSED_DIR}\")\n",
    "print(f\"  FIGURES_DIR: {FIGURES_DIR}\")\n",
    "\n",
    "# List available datasets\n",
    "if DATASET_DIR.exists():\n",
    "    datasets = [p.name for p in sorted(DATASET_DIR.iterdir()) if p.is_dir()]\n",
    "    print(f\"\\nAvailable datasets: {datasets}\")\n",
    "else:\n",
    "    print(f\"\\nWarning: Dataset directory not found at {DATASET_DIR}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Environment setup complete!\")\n",
    "print(\"=\"*80)\n"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tqdm'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mModuleNotFoundError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[2]\u001B[39m\u001B[32m, line 15\u001B[39m\n\u001B[32m     13\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mscipy\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mio\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m loadmat\n\u001B[32m     14\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mmatplotlib\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mpyplot\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mplt\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m15\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtqdm\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m tqdm\n\u001B[32m     17\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\n\u001B[32m     18\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mnn\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnn\u001B[39;00m\n",
      "\u001B[31mModuleNotFoundError\u001B[39m: No module named 'tqdm'"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89d423a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration constants and hyperparameters\n",
    "\n",
    "# Signal processing parameters\n",
    "TARGET_FS = 500           # Target sampling frequency (Hz)\n",
    "TARGET_SAMPLES = 5000     # Target number of samples per record (10 seconds at 500 Hz)\n",
    "\n",
    "# Label configuration\n",
    "LABEL_ORDER = ['MI', 'AF', 'BBB', 'NORM', 'OTHER']\n",
    "LABEL_TO_INT = {name: i for i, name in enumerate(LABEL_ORDER)}\n",
    "INT_TO_LABEL = {i: name for name, i in LABEL_TO_INT.items()}\n",
    "\n",
    "# Training hyperparameters\n",
    "BATCH_SIZE = 32           # Adjust based on GPU memory\n",
    "EPOCHS = 10               # Number of training epochs\n",
    "LR = 1e-3                 # Learning rate\n",
    "WEIGHT_DECAY = 1e-4       # L2 regularization\n",
    "NUM_WORKERS = 0           # DataLoader workers (set to 0 for Windows stability)\n",
    "PIN_MEMORY = True         # Pin memory for faster GPU transfer\n",
    "\n",
    "# Mixed precision training (GPU only)\n",
    "USE_MIXED_PRECISION = torch.cuda.is_available()\n",
    "\n",
    "# Adjust batch size for CPU\n",
    "if DEVICE.type == 'cpu' and BATCH_SIZE > 8:\n",
    "    print(f\"CPU detected - reducing batch size from {BATCH_SIZE} to 8\")\n",
    "    BATCH_SIZE = 8\n",
    "    PIN_MEMORY = False\n",
    "\n",
    "print(f\"\\nConfiguration:\")\n",
    "print(f\"  Target FS: {TARGET_FS} Hz\")\n",
    "print(f\"  Target Samples: {TARGET_SAMPLES}\")\n",
    "print(f\"  Label Mapping: {LABEL_TO_INT}\")\n",
    "print(f\"  Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"  Learning Rate: {LR}\")\n",
    "print(f\"  Epochs: {EPOCHS}\")\n",
    "print(f\"  Mixed Precision: {USE_MIXED_PRECISION}\")\n",
    "print(f\"  Device: {DEVICE}\")\n",
    "\n",
    "print(f\"\\nGPU-Intensive Tasks:\")\n",
    "print(\"  - Preprocessing: Moderate (CPU-bound mostly)\")\n",
    "print(\"  - DataLoader: Low (lazy loading)\")\n",
    "print(\"  - Model Training: HIGH (forward + backward passes)\")\n",
    "print(\"  - Model Evaluation: Medium (inference only)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eebb2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions for signal processing and file I/O\n",
    "\n",
    "def zscore_normalize(arr: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Z-score normalization: (x - mean) / std\"\"\"\n",
    "    arr = arr.astype(np.float32)\n",
    "    mean = arr.mean()\n",
    "    std = arr.std()\n",
    "    if std < 1e-8:\n",
    "        std = 1.0  # Prevent division by zero\n",
    "    return ((arr - mean) / std).astype(np.float32)\n",
    "\n",
    "\n",
    "def pad_or_truncate(x: np.ndarray, target_length: int) -> np.ndarray:\n",
    "    \"\"\"Pad with zeros or truncate to target length\"\"\"\n",
    "    if x.size >= target_length:\n",
    "        return x[:target_length]\n",
    "    pad_width = target_length - x.size\n",
    "    return np.pad(x, (0, pad_width), mode='constant', constant_values=0).astype(np.float32)\n",
    "\n",
    "\n",
    "def resample_signal(x: np.ndarray, original_fs: float, target_fs: float) -> np.ndarray:\n",
    "    \"\"\"Resample signal to target sampling frequency\"\"\"\n",
    "    if original_fs is None or np.isclose(original_fs, target_fs):\n",
    "        return x\n",
    "    new_length = int(round(x.size * target_fs / original_fs))\n",
    "    if new_length <= 0:\n",
    "        return x\n",
    "    return resample(x, new_length).astype(np.float32)\n",
    "\n",
    "\n",
    "def safe_save_npz(path: Path, signal: np.ndarray, label: int):\n",
    "    \"\"\"Save signal and label as compressed npz\"\"\"\n",
    "    np.savez_compressed(path, signal=signal.astype(np.float32), label=int(label))\n",
    "\n",
    "\n",
    "def load_npz_signal(path: Path):\n",
    "    \"\"\"Load signal and label from npz file\"\"\"\n",
    "    with np.load(path, allow_pickle=False) as data:\n",
    "        signal = data['signal']\n",
    "        label = int(data['label'])\n",
    "    return signal, label\n",
    "\n",
    "\n",
    "def read_wfdb(hea_path: Path):\n",
    "    \"\"\"Read WFDB format (.hea/.dat) and return 1D signal and sampling frequency\"\"\"\n",
    "    try:\n",
    "        import wfdb\n",
    "        record_path = str(hea_path.with_suffix(''))  # wfdb expects path without extension\n",
    "        record = wfdb.rdsamp(record_path)\n",
    "        signal = np.asarray(record[0], dtype=np.float32)\n",
    "        fs = float(record[1].get('fs', TARGET_FS))\n",
    "        \n",
    "        # Convert to 1D: average across leads or take first lead\n",
    "        if signal.ndim == 2:\n",
    "            signal_1d = signal.mean(axis=1) if signal.shape[1] > 1 else signal[:, 0]\n",
    "        else:\n",
    "            signal_1d = signal.reshape(-1)\n",
    "        \n",
    "        return signal_1d.astype(np.float32), fs\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to read WFDB file {hea_path.name}: {e}\")\n",
    "\n",
    "\n",
    "def read_mat(mat_path: Path):\n",
    "    \"\"\"Read MATLAB .mat file and return 1D signal and sampling frequency\"\"\"\n",
    "    try:\n",
    "        mat_data = loadmat(str(mat_path))\n",
    "        \n",
    "        # Try common keys for signal data\n",
    "        signal = None\n",
    "        for key in ['val', 'data', 'signal', 'ecg']:\n",
    "            if key in mat_data:\n",
    "                signal = np.asarray(mat_data[key], dtype=np.float32)\n",
    "                break\n",
    "        \n",
    "        # Fallback: find first ndarray\n",
    "        if signal is None:\n",
    "            for value in mat_data.values():\n",
    "                if isinstance(value, np.ndarray) and value.size > 100:\n",
    "                    signal = value.astype(np.float32)\n",
    "                    break\n",
    "        \n",
    "        if signal is None:\n",
    "            raise RuntimeError(\"No signal array found in MAT file\")\n",
    "        \n",
    "        # Convert to 1D\n",
    "        if signal.ndim == 2:\n",
    "            signal_1d = signal.mean(axis=0) if signal.shape[0] > 1 else signal.reshape(-1)\n",
    "        else:\n",
    "            signal_1d = signal.reshape(-1)\n",
    "        \n",
    "        # MAT files rarely contain fs info; return None\n",
    "        fs = None\n",
    "        return signal_1d.astype(np.float32), fs\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to read MAT file {mat_path.name}: {e}\")\n",
    "\n",
    "\n",
    "print(\"Utility functions defined successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49dbee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load unified label mapping from CSV\n",
    "\n",
    "UNIFIED_CSV = LOGS_DIR / \"unified_label_mapping.csv\"\n",
    "mapping_index = {}\n",
    "\n",
    "if UNIFIED_CSV.exists():\n",
    "    print(f\"Loading unified label mapping from {UNIFIED_CSV}...\")\n",
    "    df_mapping = pd.read_csv(UNIFIED_CSV, dtype=str).fillna(\"\")\n",
    "    \n",
    "    # Verify required columns\n",
    "    required_cols = {\"dataset\", \"record_id\", \"mapped_label\"}\n",
    "    if not required_cols.issubset(set(df_mapping.columns)):\n",
    "        print(f\"Warning: Missing required columns. Found: {df_mapping.columns.tolist()}\")\n",
    "        print(f\"Expected: {list(required_cols)}\")\n",
    "    else:\n",
    "        # Build mapping index with multiple key variants for robust lookup\n",
    "        for _, row in df_mapping.iterrows():\n",
    "            dataset = str(row.get(\"dataset\", \"\")).strip()\n",
    "            record_id = str(row.get(\"record_id\", \"\")).strip().replace(\"\\\\\", \"/\").strip(\"/\")\n",
    "            mapped_label = str(row.get(\"mapped_label\", \"\")).strip().upper()\n",
    "            \n",
    "            if not dataset or not record_id:\n",
    "                continue\n",
    "            \n",
    "            if dataset not in mapping_index:\n",
    "                mapping_index[dataset] = {}\n",
    "            \n",
    "            # Add full path\n",
    "            mapping_index[dataset][record_id] = mapped_label\n",
    "            \n",
    "            # Add variants for robust matching\n",
    "            parts = record_id.split(\"/\")\n",
    "            if len(parts) >= 1:\n",
    "                mapping_index[dataset][parts[-1]] = mapped_label  # basename\n",
    "            if len(parts) >= 2:\n",
    "                mapping_index[dataset][\"/\".join(parts[-2:])] = mapped_label  # last two components\n",
    "        \n",
    "        print(f\"Loaded {len(df_mapping)} mappings from {len(mapping_index)} datasets\")\n",
    "        \n",
    "        # Count mappings per label\n",
    "        label_counts = Counter(df_mapping['mapped_label'].str.upper())\n",
    "        print(f\"\\nLabel distribution in mapping:\")\n",
    "        for label in LABEL_ORDER:\n",
    "            count = label_counts.get(label, 0)\n",
    "            print(f\"  {label}: {count:,}\")\n",
    "        unmapped = label_counts.get('', 0)\n",
    "        print(f\"  (unmapped): {unmapped:,}\")\n",
    "else:\n",
    "    print(f\"Warning: Unified label mapping not found at {UNIFIED_CSV}\")\n",
    "    print(\"All records will be labeled as OTHER\")\n",
    "\n",
    "\n",
    "def lookup_mapped_label(path: Path) -> str:\n",
    "    \"\"\"Look up mapped label for a given file path\"\"\"\n",
    "    try:\n",
    "        rel_path = path.relative_to(DATASET_DIR).with_suffix(\"\")\n",
    "    except Exception:\n",
    "        rel_path = path.with_suffix(\"\")\n",
    "    \n",
    "    parts = rel_path.as_posix().split(\"/\")\n",
    "    dataset = parts[0] if parts else \"\"\n",
    "    \n",
    "    if dataset not in mapping_index:\n",
    "        return \"OTHER\"\n",
    "    \n",
    "    index = mapping_index[dataset]\n",
    "    \n",
    "    # Try multiple key variants\n",
    "    candidates = [\n",
    "        rel_path.as_posix(),                              # full path\n",
    "        \"/\".join(parts[1:]) if len(parts) > 1 else \"\",   # without dataset prefix\n",
    "        \"/\".join(parts[-2:]) if len(parts) >= 2 else \"\", # last two components\n",
    "        rel_path.name                                     # basename only\n",
    "    ]\n",
    "    \n",
    "    for key in candidates:\n",
    "        if key and key in index:\n",
    "            label = index[key].upper()\n",
    "            return label if label in LABEL_TO_INT else \"OTHER\"\n",
    "    \n",
    "    # CinC2017 special case\n",
    "    if \"CinC\" in dataset and len(parts) >= 3:\n",
    "        alt_key = \"/\".join(parts[2:])\n",
    "        if alt_key in index:\n",
    "            label = index[alt_key].upper()\n",
    "            return label if label in LABEL_TO_INT else \"OTHER\"\n",
    "    \n",
    "    return \"OTHER\"\n",
    "\n",
    "\n",
    "print(\"Label lookup function ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09abcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streaming preprocessing: scan datasets, process, and save per-record npz files\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"STARTING PREPROCESSING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Find all .hea and .mat files\n",
    "print(f\"\\nScanning {DATASET_DIR} for ECG files...\")\n",
    "hea_files = sorted(DATASET_DIR.rglob(\"*.hea\"))\n",
    "mat_files = sorted(DATASET_DIR.rglob(\"*.mat\"))\n",
    "all_files = hea_files + mat_files\n",
    "\n",
    "print(f\"Found {len(hea_files)} .hea files and {len(mat_files)} .mat files\")\n",
    "print(f\"Total files to process: {len(all_files)}\")\n",
    "\n",
    "if not all_files:\n",
    "    print(\"\\nNo dataset files found. Generating synthetic records for testing...\")\n",
    "    # Generate synthetic signals\n",
    "    for i in range(20):\n",
    "        t = np.linspace(0, TARGET_SAMPLES / TARGET_FS, TARGET_SAMPLES, dtype=np.float32)\n",
    "        freq = 0.5 + 0.1 * i\n",
    "        signal = np.sin(2 * np.pi * freq * t).astype(np.float32)\n",
    "        signal = signal[np.newaxis, :]  # Shape: (1, TARGET_SAMPLES)\n",
    "        \n",
    "        label = i % len(LABEL_ORDER)\n",
    "        out_file = RECORDS_DIR / f\"SYNTH_{i:04d}.npz\"\n",
    "        safe_save_npz(out_file, signal, label)\n",
    "    \n",
    "    print(f\"Generated 20 synthetic records in {RECORDS_DIR}\")\n",
    "else:\n",
    "    # Process real dataset files\n",
    "    manifest = []\n",
    "    label_counts = Counter()\n",
    "    skipped = 0\n",
    "    \n",
    "    print(f\"\\nProcessing files...\")\n",
    "    progress_bar = tqdm(all_files, desc=\"Processing\", unit=\"file\")\n",
    "    \n",
    "    for file_path in progress_bar:\n",
    "        try:\n",
    "            # Read signal\n",
    "            if file_path.suffix.lower() == '.hea':\n",
    "                signal, fs = read_wfdb(file_path)\n",
    "            else:\n",
    "                signal, fs = read_mat(file_path)\n",
    "            \n",
    "            # Resample if needed\n",
    "            if fs is not None and not np.isclose(fs, TARGET_FS):\n",
    "                signal = resample_signal(signal, fs, TARGET_FS)\n",
    "            \n",
    "            # Normalize\n",
    "            signal = zscore_normalize(signal)\n",
    "            \n",
    "            # Pad or truncate\n",
    "            signal = pad_or_truncate(signal, TARGET_SAMPLES)\n",
    "            \n",
    "            # Add channel dimension: (1, TARGET_SAMPLES)\n",
    "            signal = signal[np.newaxis, :]\n",
    "            \n",
    "            # Lookup label\n",
    "            mapped_label = lookup_mapped_label(file_path)\n",
    "            label_int = LABEL_TO_INT.get(mapped_label, LABEL_TO_INT[\"OTHER\"])\n",
    "            \n",
    "            # Generate safe filename\n",
    "            try:\n",
    "                rel_path = file_path.relative_to(DATASET_DIR).with_suffix(\"\")\n",
    "                record_id = rel_path.as_posix().replace(\"/\", \"__\")\n",
    "            except Exception:\n",
    "                record_id = file_path.stem\n",
    "            \n",
    "            # Save processed record\n",
    "            out_file = RECORDS_DIR / f\"{record_id}.npz\"\n",
    "            safe_save_npz(out_file, signal, label_int)\n",
    "            \n",
    "            # Update manifest\n",
    "            manifest.append({\n",
    "                \"path\": f\"records/{out_file.name}\",\n",
    "                \"label\": int(label_int)\n",
    "            })\n",
    "            label_counts[label_int] += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            skipped += 1\n",
    "            if skipped <= 10:  # Only print first 10 errors\n",
    "                tqdm.write(f\"Error processing {file_path.name}: {e}\")\n",
    "            progress_bar.set_postfix({\"skipped\": skipped})\n",
    "    \n",
    "    progress_bar.close()\n",
    "    \n",
    "    print(f\"\\n\" + \"=\"*80)\n",
    "    print(\"PREPROCESSING SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Total files processed: {len(manifest):,}\")\n",
    "    print(f\"Files skipped (errors): {skipped:,}\")\n",
    "    print(f\"\\nLabel distribution:\")\n",
    "    for idx, label_name in enumerate(LABEL_ORDER):\n",
    "        count = label_counts[idx]\n",
    "        pct = (count / len(manifest) * 100) if manifest else 0\n",
    "        print(f\"  {idx}={label_name:5s}: {count:6,d} ({pct:5.1f}%)\")\n",
    "    \n",
    "    # Save manifest and create splits\n",
    "    print(f\"\\nCreating stratified train/val/test splits (80/10/10)...\")\n",
    "    \n",
    "    # Group by label\n",
    "    by_label = defaultdict(list)\n",
    "    for entry in manifest:\n",
    "        by_label[entry['label']].append(entry)\n",
    "    \n",
    "    # Split each label class\n",
    "    train_list, val_list, test_list = [], [], []\n",
    "    rng = np.random.default_rng(seed=DEFAULT_SEED)\n",
    "    \n",
    "    for label, entries in by_label.items():\n",
    "        rng.shuffle(entries)\n",
    "        n = len(entries)\n",
    "        n_train = int(n * 0.80)\n",
    "        n_val = int(n * 0.10)\n",
    "        \n",
    "        train_list.extend(entries[:n_train])\n",
    "        val_list.extend(entries[n_train:n_train + n_val])\n",
    "        test_list.extend(entries[n_train + n_val:])\n",
    "    \n",
    "    # Save splits.json\n",
    "    splits_data = {\n",
    "        \"timestamp\": pd.Timestamp.utcnow().isoformat(),\n",
    "        \"label_order\": LABEL_ORDER,\n",
    "        \"label_to_int\": LABEL_TO_INT,\n",
    "        \"train\": train_list,\n",
    "        \"val\": val_list,\n",
    "        \"test\": test_list,\n",
    "        \"counts\": {\n",
    "            \"train\": len(train_list),\n",
    "            \"val\": len(val_list),\n",
    "            \"test\": len(test_list)\n",
    "        },\n",
    "        \"class_counts\": {int(k): int(v) for k, v in label_counts.items()}\n",
    "    }\n",
    "    \n",
    "    splits_file = PROCESSED_DIR / \"splits.json\"\n",
    "    with open(splits_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(splits_data, f, indent=2)\n",
    "    \n",
    "    # Save label_map.json\n",
    "    label_map = {\n",
    "        \"label_to_int\": LABEL_TO_INT,\n",
    "        \"int_to_label\": INT_TO_LABEL\n",
    "    }\n",
    "    label_map_file = PROCESSED_DIR / \"label_map.json\"\n",
    "    with open(label_map_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(label_map, f, indent=2)\n",
    "    \n",
    "    # Save labels.npy\n",
    "    np.save(PROCESSED_DIR / \"labels.npy\", np.array(LABEL_ORDER, dtype=object))\n",
    "    \n",
    "    print(f\"\\nSaved:\")\n",
    "    print(f\"  - {splits_file}\")\n",
    "    print(f\"  - {label_map_file}\")\n",
    "    print(f\"  - {PROCESSED_DIR / 'labels.npy'}\")\n",
    "    print(f\"\\nSplit sizes:\")\n",
    "    print(f\"  Train: {len(train_list):,}\")\n",
    "    print(f\"  Val:   {len(val_list):,}\")\n",
    "    print(f\"  Test:  {len(test_list):,}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PREPROCESSING COMPLETED SUCCESSFULLY\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52438321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch Dataset for lazy loading of per-record npz files\n",
    "\n",
    "class ECGDataset(Dataset):\n",
    "    \"\"\"Lazy-loading dataset for preprocessed ECG records\"\"\"\n",
    "    \n",
    "    def __init__(self, entries, base_dir):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            entries: List of dicts with 'path' and 'label' keys\n",
    "            base_dir: Base directory for processed files\n",
    "        \"\"\"\n",
    "        self.entries = entries\n",
    "        self.base_dir = Path(base_dir)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.entries)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        entry = self.entries[idx]\n",
    "        file_path = self.base_dir / entry['path']\n",
    "        \n",
    "        # Load signal and label\n",
    "        signal, label = load_npz_signal(file_path)\n",
    "        \n",
    "        # Convert to tensors\n",
    "        signal_tensor = torch.from_numpy(signal).float()\n",
    "        label_tensor = torch.tensor(label, dtype=torch.long)\n",
    "        \n",
    "        return signal_tensor, label_tensor\n",
    "\n",
    "\n",
    "def create_dataloaders(splits_file, processed_dir, batch_size, num_workers=0, pin_memory=False):\n",
    "    \"\"\"Create train, val, and test DataLoaders\"\"\"\n",
    "    \n",
    "    with open(splits_file, 'r') as f:\n",
    "        splits = json.load(f)\n",
    "    \n",
    "    train_dataset = ECGDataset(splits['train'], processed_dir)\n",
    "    val_dataset = ECGDataset(splits['val'], processed_dir)\n",
    "    test_dataset = ECGDataset(splits['test'], processed_dir)\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory\n",
    "    )\n",
    "    \n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "\n",
    "# Create DataLoaders\n",
    "print(\"Creating DataLoaders...\")\n",
    "splits_file = PROCESSED_DIR / \"splits.json\"\n",
    "\n",
    "if splits_file.exists():\n",
    "    train_loader, val_loader, test_loader = create_dataloaders(\n",
    "        splits_file, \n",
    "        PROCESSED_DIR,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=PIN_MEMORY\n",
    "    )\n",
    "    \n",
    "    print(f\"DataLoaders created:\")\n",
    "    print(f\"  Train batches: {len(train_loader)}\")\n",
    "    print(f\"  Val batches:   {len(val_loader)}\")\n",
    "    print(f\"  Test batches:  {len(test_loader)}\")\n",
    "    \n",
    "    # Show example batch\n",
    "    sample_batch = next(iter(train_loader))\n",
    "    print(f\"\\nExample batch shapes:\")\n",
    "    print(f\"  Signals: {sample_batch[0].shape}\")\n",
    "    print(f\"  Labels:  {sample_batch[1].shape}\")\n",
    "    print(f\"  Label values: {sample_batch[1][:min(10, BATCH_SIZE)].tolist()}\")\n",
    "else:\n",
    "    print(f\"Error: splits.json not found at {splits_file}\")\n",
    "    print(\"Please run the preprocessing cell first.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fad8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D CNN Model for ECG Classification\n",
    "\n",
    "class ECGNet1D(nn.Module):\n",
    "    \"\"\"Compact 1D CNN for ECG signal classification\"\"\"\n",
    "    \n",
    "    def __init__(self, n_classes=len(LABEL_ORDER), input_channels=1, base_channels=32, dropout=0.3):\n",
    "        super(ECGNet1D, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(input_channels, base_channels, kernel_size=7, stride=2, padding=3)\n",
    "        self.bn1 = nn.BatchNorm1d(base_channels)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(base_channels, base_channels * 2, kernel_size=5, stride=2, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(base_channels * 2)\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(base_channels * 2, base_channels * 4, kernel_size=3, stride=2, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(base_channels * 4)\n",
    "        \n",
    "        self.conv4 = nn.Conv1d(base_channels * 4, base_channels * 8, kernel_size=3, stride=2, padding=1)\n",
    "        self.bn4 = nn.BatchNorm1d(base_channels * 8)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(base_channels * 8, n_classes)\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, 1, samples)\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.relu(self.bn4(self.conv4(x)))\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Instantiate model\n",
    "model = ECGNet1D(n_classes=len(LABEL_ORDER), base_channels=32, dropout=0.3)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"MODEL\")\n",
    "print(\"=\"*80)\n",
    "print(model)\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"Model device: {DEVICE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0750ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop with mixed precision and metrics tracking\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "\n",
    "# Mixed precision scaler\n",
    "scaler = torch.cuda.amp.GradScaler() if USE_MIXED_PRECISION else None\n",
    "\n",
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'train_f1': [],\n",
    "    'val_loss': [],\n",
    "    'val_acc': [],\n",
    "    'val_f1': [],\n",
    "    'lr': []\n",
    "}\n",
    "\n",
    "best_val_f1 = 0.0\n",
    "best_epoch = 0\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TRAINING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{EPOCHS}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_preds = []\n",
    "    train_labels = []\n",
    "    \n",
    "    train_progress = tqdm(train_loader, desc=\"Training\", leave=False)\n",
    "    for signals, labels in train_progress:\n",
    "        signals = signals.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Mixed precision forward pass\n",
    "        if USE_MIXED_PRECISION:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(signals)\n",
    "                loss = criterion(outputs, labels)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            outputs = model(signals)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        preds = outputs.argmax(dim=1).cpu().numpy()\n",
    "        train_preds.extend(preds)\n",
    "        train_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        train_progress.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    train_loss /= len(train_loader)\n",
    "    train_acc = (np.array(train_preds) == np.array(train_labels)).mean()\n",
    "    train_f1 = f1_score(train_labels, train_preds, average='macro', zero_division=0)\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_preds = []\n",
    "    val_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        val_progress = tqdm(val_loader, desc=\"Validation\", leave=False)\n",
    "        for signals, labels in val_progress:\n",
    "            signals = signals.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "            \n",
    "            outputs = model(signals)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            preds = outputs.argmax(dim=1).cpu().numpy()\n",
    "            val_preds.extend(preds)\n",
    "            val_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    val_loss /= len(val_loader)\n",
    "    val_acc = (np.array(val_preds) == np.array(val_labels)).mean()\n",
    "    val_f1 = f1_score(val_labels, val_preds, average='macro', zero_division=0)\n",
    "    \n",
    "    # Update history\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['train_f1'].append(train_f1)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['val_f1'].append(val_f1)\n",
    "    history['lr'].append(current_lr)\n",
    "    \n",
    "    # Print epoch summary\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Train F1: {train_f1:.4f}\")\n",
    "    print(f\"Val Loss:   {val_loss:.4f} | Val Acc:   {val_acc:.4f} | Val F1:   {val_f1:.4f}\")\n",
    "    print(f\"LR: {current_lr:.6f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_f1 > best_val_f1:\n",
    "        best_val_f1 = val_f1\n",
    "        best_epoch = epoch + 1\n",
    "        best_model_path = CHECKPOINTS_DIR / \"best_model.pth\"\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_f1': val_f1,\n",
    "            'val_acc': val_acc,\n",
    "            'val_loss': val_loss\n",
    "        }, best_model_path)\n",
    "        print(f\"✓ Saved best model (F1: {val_f1:.4f})\")\n",
    "    \n",
    "    # Step scheduler\n",
    "    scheduler.step()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING COMPLETED\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Best validation F1: {best_val_f1:.4f} (Epoch {best_epoch})\")\n",
    "\n",
    "# Save final model\n",
    "final_model_path = CHECKPOINTS_DIR / \"final_model.pth\"\n",
    "torch.save({\n",
    "    'epoch': EPOCHS,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'history': history\n",
    "}, final_model_path)\n",
    "print(f\"\\nSaved final model to {final_model_path}\")\n",
    "\n",
    "# Save training history\n",
    "history_file = PROCESSED_DIR / \"training_history.json\"\n",
    "with open(history_file, 'w') as f:\n",
    "    json.dump(history, f, indent=2)\n",
    "print(f\"Saved training history to {history_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef430d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation on test set with metrics and visualizations\n",
    "\n",
    "# Load best model\n",
    "best_model_path = CHECKPOINTS_DIR / \"best_model.pth\"\n",
    "checkpoint = torch.load(best_model_path, map_location=DEVICE)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(f\"Loaded best model from epoch {checkpoint['epoch'] + 1}\")\n",
    "print(f\"Best validation F1: {checkpoint['val_f1']:.4f}\")\n",
    "\n",
    "# Evaluate on test set\n",
    "model.eval()\n",
    "test_preds = []\n",
    "test_labels = []\n",
    "test_probs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_progress = tqdm(test_loader, desc=\"Testing\")\n",
    "    for signals, labels in test_progress:\n",
    "        signals = signals.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        \n",
    "        outputs = model(signals)\n",
    "        probs = F.softmax(outputs, dim=1)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        \n",
    "        test_probs.append(probs.cpu().numpy())\n",
    "        test_preds.extend(preds.cpu().numpy())\n",
    "        test_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "test_probs = np.vstack(test_probs)\n",
    "test_preds = np.array(test_preds)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "# Calculate metrics\n",
    "test_acc = (test_preds == test_labels).mean()\n",
    "test_f1_macro = f1_score(test_labels, test_preds, average='macro', zero_division=0)\n",
    "test_f1_weighted = f1_score(test_labels, test_preds, average='weighted', zero_division=0)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TEST SET EVALUATION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "print(f\"Test F1 (macro): {test_f1_macro:.4f}\")\n",
    "print(f\"Test F1 (weighted): {test_f1_weighted:.4f}\")\n",
    "\n",
    "# Per-class metrics\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"Per-Class Metrics:\")\n",
    "print(\"-\"*80)\n",
    "precision, recall, f1, support = precision_recall_fscore_support(\n",
    "    test_labels, test_preds, average=None, zero_division=0\n",
    ")\n",
    "\n",
    "for i, label_name in enumerate(LABEL_ORDER):\n",
    "    print(f\"{label_name:5s}: Precision={precision[i]:.3f}, Recall={recall[i]:.3f}, F1={f1[i]:.3f}, Support={support[i]}\")\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(test_labels, test_preds)\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(\"-\"*80)\n",
    "print(cm)\n",
    "\n",
    "# Save evaluation results\n",
    "eval_results = {\n",
    "    'test_accuracy': float(test_acc),\n",
    "    'test_f1_macro': float(test_f1_macro),\n",
    "    'test_f1_weighted': float(test_f1_weighted),\n",
    "    'per_class_metrics': {\n",
    "        LABEL_ORDER[i]: {\n",
    "            'precision': float(precision[i]),\n",
    "            'recall': float(recall[i]),\n",
    "            'f1': float(f1[i]),\n",
    "            'support': int(support[i])\n",
    "        }\n",
    "        for i in range(len(LABEL_ORDER))\n",
    "    },\n",
    "    'confusion_matrix': cm.tolist()\n",
    "}\n",
    "\n",
    "eval_file = PROCESSED_DIR / \"evaluation_results.json\"\n",
    "with open(eval_file, 'w') as f:\n",
    "    json.dump(eval_results, f, indent=2)\n",
    "print(f\"\\nSaved evaluation results to {eval_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a579fa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and save visualization plots\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams['savefig.dpi'] = 150\n",
    "\n",
    "# 1. Training curves\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Loss\n",
    "axes[0, 0].plot(history['train_loss'], label='Train Loss', linewidth=2)\n",
    "axes[0, 0].plot(history['val_loss'], label='Val Loss', linewidth=2)\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].set_title('Training and Validation Loss')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy\n",
    "axes[0, 1].plot(history['train_acc'], label='Train Accuracy', linewidth=2)\n",
    "axes[0, 1].plot(history['val_acc'], label='Val Accuracy', linewidth=2)\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Accuracy')\n",
    "axes[0, 1].set_title('Training and Validation Accuracy')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# F1 Score\n",
    "axes[1, 0].plot(history['train_f1'], label='Train F1', linewidth=2)\n",
    "axes[1, 0].plot(history['val_f1'], label='Val F1', linewidth=2)\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('F1 Score (macro)')\n",
    "axes[1, 0].set_title('Training and Validation F1 Score')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Learning Rate\n",
    "axes[1, 1].plot(history['lr'], label='Learning Rate', linewidth=2, color='orange')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('Learning Rate')\n",
    "axes[1, 1].set_title('Learning Rate Schedule')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "axes[1, 1].set_yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "training_curves_path = FIGURES_DIR / 'training_curves.png'\n",
    "plt.savefig(training_curves_path, bbox_inches='tight')\n",
    "print(f\"Saved training curves to {training_curves_path}\")\n",
    "plt.show()\n",
    "\n",
    "# 2. Confusion Matrix Heatmap\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "im = ax.imshow(cm, interpolation='nearest', cmap='Blues')\n",
    "ax.figure.colorbar(im, ax=ax)\n",
    "ax.set(xticks=np.arange(cm.shape[1]),\n",
    "       yticks=np.arange(cm.shape[0]),\n",
    "       xticklabels=LABEL_ORDER,\n",
    "       yticklabels=LABEL_ORDER,\n",
    "       xlabel='Predicted Label',\n",
    "       ylabel='True Label',\n",
    "       title='Confusion Matrix')\n",
    "\n",
    "# Add text annotations\n",
    "thresh = cm.max() / 2.0\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        ax.text(j, i, format(cm[i, j], 'd'),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm[i, j] > thresh else \"black\",\n",
    "                fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "cm_path = FIGURES_DIR / 'confusion_matrix.png'\n",
    "plt.savefig(cm_path, bbox_inches='tight')\n",
    "print(f\"Saved confusion matrix to {cm_path}\")\n",
    "plt.show()\n",
    "\n",
    "# 3. Per-class F1 Score Bar Plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "x = np.arange(len(LABEL_ORDER))\n",
    "bars = ax.bar(x, f1, color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd'])\n",
    "ax.set_xlabel('Class', fontsize=12)\n",
    "ax.set_ylabel('F1 Score', fontsize=12)\n",
    "ax.set_title('Per-Class F1 Score on Test Set', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(LABEL_ORDER)\n",
    "ax.set_ylim([0, 1.0])\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (bar, value) in enumerate(zip(bars, f1)):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width() / 2.0, height + 0.02,\n",
    "            f'{value:.3f}',\n",
    "            ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "f1_bars_path = FIGURES_DIR / 'per_class_f1.png'\n",
    "plt.savefig(f1_bars_path, bbox_inches='tight')\n",
    "print(f\"Saved per-class F1 plot to {f1_bars_path}\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nAll visualizations saved to:\", FIGURES_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2322e1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automated smoke tests to verify pipeline integrity\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"SMOKE TESTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Test 1: Load a single record\n",
    "print(\"\\n1. Testing record loading...\")\n",
    "try:\n",
    "    test_files = list(RECORDS_DIR.glob(\"*.npz\"))\n",
    "    if test_files:\n",
    "        test_file = test_files[0]\n",
    "        signal, label = load_npz_signal(test_file)\n",
    "        print(f\"   ✓ Loaded {test_file.name}\")\n",
    "        print(f\"     Signal shape: {signal.shape}\")\n",
    "        print(f\"     Label: {label} ({LABEL_ORDER[label]})\")\n",
    "        assert signal.shape[1] == TARGET_SAMPLES, \"Signal length mismatch\"\n",
    "        assert 0 <= label < len(LABEL_ORDER), \"Invalid label\"\n",
    "        print(\"   ✓ Record validation passed\")\n",
    "    else:\n",
    "        print(\"   ✗ No records found\")\n",
    "except Exception as e:\n",
    "    print(f\"   ✗ Failed: {e}\")\n",
    "\n",
    "# Test 2: Model forward pass\n",
    "print(\"\\n2. Testing model forward pass...\")\n",
    "try:\n",
    "    dummy_input = torch.randn(1, 1, TARGET_SAMPLES).to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        output = model(dummy_input)\n",
    "    print(f\"   ✓ Input shape: {dummy_input.shape}\")\n",
    "    print(f\"   ✓ Output shape: {output.shape}\")\n",
    "    assert output.shape == (1, len(LABEL_ORDER)), \"Output shape mismatch\"\n",
    "    print(\"   ✓ Model forward pass successful\")\n",
    "except Exception as e:\n",
    "    print(f\"   ✗ Failed: {e}\")\n",
    "\n",
    "# Test 3: Checkpoint loading\n",
    "print(\"\\n3. Testing checkpoint loading...\")\n",
    "try:\n",
    "    best_checkpoint = CHECKPOINTS_DIR / \"best_model.pth\"\n",
    "    if best_checkpoint.exists():\n",
    "        checkpoint = torch.load(best_checkpoint, map_location=DEVICE)\n",
    "        print(f\"   ✓ Loaded checkpoint from epoch {checkpoint.get('epoch', 'unknown')}\")\n",
    "        print(f\"   ✓ Val F1: {checkpoint.get('val_f1', 0):.4f}\")\n",
    "        print(\"   ✓ Checkpoint loading successful\")\n",
    "    else:\n",
    "        print(f\"   ✗ Checkpoint not found at {best_checkpoint}\")\n",
    "except Exception as e:\n",
    "    print(f\"   ✗ Failed: {e}\")\n",
    "\n",
    "# Test 4: Dataset integrity\n",
    "print(\"\\n4. Testing dataset integrity...\")\n",
    "try:\n",
    "    splits_file = PROCESSED_DIR / \"splits.json\"\n",
    "    if splits_file.exists():\n",
    "        with open(splits_file, 'r') as f:\n",
    "            splits = json.load(f)\n",
    "        n_train = len(splits.get('train', []))\n",
    "        n_val = len(splits.get('val', []))\n",
    "        n_test = len(splits.get('test', []))\n",
    "        n_total = n_train + n_val + n_test\n",
    "        print(f\"   ✓ Total records: {n_total}\")\n",
    "        print(f\"   ✓ Train: {n_train}, Val: {n_val}, Test: {n_test}\")\n",
    "        print(\"   ✓ Dataset integrity check passed\")\n",
    "    else:\n",
    "        print(f\"   ✗ Splits file not found\")\n",
    "except Exception as e:\n",
    "    print(f\"   ✗ Failed: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SMOKE TESTS COMPLETED\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5c4fab",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Pipeline Complete!\n",
    "\n",
    "This notebook has successfully completed the full ECG classification pipeline:\n",
    "\n",
    "✓ **Preprocessing**: Loaded, resampled, normalized, and saved ECG records  \n",
    "✓ **Dataset**: Created stratified train/val/test splits  \n",
    "✓ **Model**: Trained 1D CNN classifier  \n",
    "✓ **Evaluation**: Generated metrics and visualizations  \n",
    "✓ **Artifacts**: Saved models, checkpoints, and results  \n",
    "\n",
    "### Output Files\n",
    "\n",
    "- **Processed Data**: `artifacts/processed/records/*.npz`\n",
    "- **Splits**: `artifacts/processed/splits.json`\n",
    "- **Best Model**: `artifacts/processed/checkpoints/best_model.pth`\n",
    "- **Training History**: `artifacts/processed/training_history.json`\n",
    "- **Evaluation Results**: `artifacts/processed/evaluation_results.json`\n",
    "- **Figures**: `artifacts/figures/*.png`\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Improve Model**: Experiment with deeper architectures (ResNet1D, attention mechanisms)\n",
    "2. **Hyperparameter Tuning**: Use grid search or Bayesian optimization\n",
    "3. **Data Augmentation**: Add noise, scaling, time-warping\n",
    "4. **Multi-Lead Models**: Process all 12 leads instead of averaging\n",
    "5. **Ensemble Methods**: Combine multiple models for better performance\n",
    "6. **Deployment**: Export to ONNX or TorchScript for production\n",
    "\n",
    "### Inference Example\n",
    "\n",
    "To use the trained model for inference:\n",
    "\n",
    "```python\n",
    "# Load model\n",
    "checkpoint = torch.load('artifacts/processed/checkpoints/best_model.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "# Load a signal\n",
    "signal, label = load_npz_signal('path/to/record.npz')\n",
    "signal_tensor = torch.from_numpy(signal).float().unsqueeze(0).to(DEVICE)\n",
    "\n",
    "# Predict\n",
    "with torch.no_grad():\n",
    "    output = model(signal_tensor)\n",
    "    probabilities = F.softmax(output, dim=1)\n",
    "    predicted_class = output.argmax(dim=1).item()\n",
    "    predicted_label = LABEL_ORDER[predicted_class]\n",
    "\n",
    "print(f\"Predicted: {predicted_label} (confidence: {probabilities[0, predicted_class]:.2%})\")\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ECG Research",
   "language": "python",
   "name": "ecg-research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
