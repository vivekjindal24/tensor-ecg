{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Master ECG Pipeline\n",
        "\n",
        "This notebook combines all project scripts and modules into one single runnable file.\n",
        "\n",
        "**Usage:** run cells top-to-bottom. For headless execution on Windows use:\n",
        "\n",
        "```python\n",
        "import asyncio, sys\n",
        "if sys.platform == 'win32':\n",
        "    asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "\n",
        "# Environment & imports - idempotent\n",
        "import os, sys, json, time, math, asyncio\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "print('Python:', sys.executable)\n",
        "print('Torch:', getattr(torch, '__version__', 'n/a'))\n",
        "# Windows asyncio fix for nbconvert headless runs\n",
        "import platform\n",
        "if platform.system() == 'Windows':\n",
        "    try:\n",
        "        import asyncio, sys\n",
        "        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "# Project root detection\n",
        "ROOT = Path(os.environ.get('ECG_ROOT', Path.cwd().resolve()))\n",
        "DATASET_DIR = ROOT / 'Dataset'\n",
        "ARTIFACTS_DIR = ROOT / 'artifacts'\n",
        "PROCESSED_DIR = ARTIFACTS_DIR / 'processed'\n",
        "LOGS_DIR = ROOT / 'logs'\n",
        "NOTEBOOKS_DIR = ROOT / 'notebooks'\n",
        "for p in (ARTIFACTS_DIR, PROCESSED_DIR, PROCESSED_DIR/'records', LOGS_DIR):\n",
        "    p.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# seeds for reproducibility\n",
        "SEED = int(os.environ.get('ECG_SEED', '42'))\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('DEVICE', DEVICE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Quick: Generate/Load unified mapping (run this cell)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "\n",
        "# Generate unified mapping (if you have script)\n",
        "candidate = Path('logs/unified_label_mapping.candidate.csv')\n",
        "prod = Path('logs/unified_label_mapping.csv')\n",
        "if (Path('scripts/generate_unified_mapping.py')).exists() and not candidate.exists():\n",
        "    print('Generating candidate mapping...')\n",
        "    os.system(f'python \"{str(Path(\"scripts/generate_unified_mapping.py\"))}\"')\n",
        "else:\n",
        "    print('Candidate mapping exists:', candidate.exists(), 'Prod file exists:', prod.exists())\n",
        "# If you have a candidate and want to promote it, uncomment:\n",
        "# if candidate.exists(): candidate.replace(prod)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preprocessing (streaming, memory-safe)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "\n",
        "# Run streaming preprocessing from scripts/preprocess_streaming.py if present\n",
        "proc_script = Path('scripts/preprocess_streaming.py')\n",
        "if proc_script.exists():\n",
        "    print('Launching streaming preprocessing (script)...')\n",
        "    # recommend using environment var ECG_PREPROCESS_LIMIT to test\n",
        "    os.system(f'python \"{proc_script}\"')\n",
        "else:\n",
        "    print('No preprocess_streaming.py found. Implement preprocessing in this notebook or inline alternate script.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training (run this after preprocessing finishes)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "\n",
        "# Launch training script if present\n",
        "train_script = Path('scripts/train_pipeline.py')  # optional\n",
        "if train_script.exists():\n",
        "    print('Running training script...')\n",
        "    os.system(f'python \"{train_script}\"')\n",
        "else:\n",
        "    print('No training script detected. Use in-notebook training cells or create scripts/training.py and link it.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluation and Visuals\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "\n",
        "# Run evaluation if script exists\n",
        "eval_script = Path('scripts/evaluate.py')\n",
        "if eval_script.exists():\n",
        "    os.system(f'python \"{eval_script}\"')\n",
        "else:\n",
        "    print('No evaluate.py. Use notebook cells to visualize artifacts/figures/')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Smoke tests and quick validation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "\n",
        "# Run smoke tests\n",
        "smoke = Path('scripts/verify_smoke_test.py')\n",
        "if smoke.exists():\n",
        "    os.system(f'python \"{smoke}\"')\n",
        "else:\n",
        "    print('No smoke-test script. Manual checks:')\n",
        "    print(' - Count files:', len(list((PROCESSED_DIR/'records').glob('*.npz'))))\n",
        "    print(' - Check splits:', (PROCESSED_DIR/'splits.json').exists())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Final: Notebook control\n",
        "You can now run cells in order. Long-running steps are executed as external scripts to avoid kernel timeouts.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}