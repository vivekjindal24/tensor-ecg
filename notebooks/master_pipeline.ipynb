{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c7566aa",
   "metadata": {},
   "source": [
    "# ECG Master Pipeline - Production Training Ready\n",
    "\n",
    "Complete notebook-based pipeline for ECG classification with preprocessing, robust training, evaluation and inference.\n",
    "\n",
    "## Quick Start Commands\n",
    "\n",
    "**Headless execution (recommended for full runs):**\n",
    "```powershell\n",
    "jupyter nbconvert --to notebook --execute notebooks/master_pipeline.ipynb --ExecutePreprocessor.timeout=-1 --output logs/run_$(Get-Date -Format 'yyyyMMdd_HHmmss').ipynb\n",
    "```\n",
    "\n",
    "**Interactive modes:**\n",
    "- Quick smoke test (256 samples): Run the \"QUICK SMOKE RUN\" cell\n",
    "- Medium run (5k samples): Set `ECG_PREPROCESS_LIMIT=5000` in config, run training cells\n",
    "- Full production: Set `ECG_PREPROCESS_LIMIT=0` (no limit), run training cells\n",
    "\n",
    "## Notes\n",
    "- Windows asyncio fix applied automatically in environment setup\n",
    "- GPU auto-detection with fallback to CPU\n",
    "- Mixed precision training enabled automatically on CUDA\n",
    "- All artifacts saved to `artifacts/`, logs to `logs/`\n",
    "- Checkpoints saved every epoch + best model by val F1\n",
    "\n",
    "---\n",
    "**Sections:** Config → Environment → Utilities → Mapping → Preprocessing → Dataset → Model → Training → Evaluation → Inference → Runbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "002dec38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T06:16:16.006839Z",
     "start_time": "2025-12-02T06:16:15.988052Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Adjusted] ROOT from D:\\ecg-research\\notebooks -> D:\\ecg-research\n",
      "ROOT: D:\\ecg-research\n",
      "DATASET_DIR: D:\\ecg-research\\Dataset\n",
      "DATASET_DIR exists: True\n",
      "Dataset subdirectories: ['PTB_Diagnostic', 'CinC2017', 'Chapman_Shaoxing', 'ptb-xl']\n",
      "ARTIFACTS_DIR: D:\\ecg-research\\artifacts\n",
      "PROCESSED_DIR: D:\\ecg-research\\artifacts\\processed\n"
     ]
    }
   ],
   "source": [
    "# Environment checks and directory setup\n",
    "import os, sys, asyncio\n",
    "if sys.platform == \"win32\":\n",
    "    try:\n",
    "        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "from pathlib import Path\n",
    "# Find project root by looking for Dataset folder or going up from cwd\n",
    "ROOT = Path.cwd().resolve()\n",
    "initial_root = ROOT\n",
    "# If we're in notebooks/ subdirectory, go up one level\n",
    "if ROOT.name == 'notebooks' and (ROOT.parent / 'Dataset').exists():\n",
    "    ROOT = ROOT.parent\n",
    "    print(f'[Adjusted] ROOT from {initial_root} -> {ROOT}')\n",
    "# If still no Dataset found, try going up one more level\n",
    "elif not (ROOT / 'Dataset').exists() and (ROOT.parent / 'Dataset').exists():\n",
    "    ROOT = ROOT.parent\n",
    "    print(f'[Adjusted] ROOT from {initial_root} -> {ROOT}')\n",
    "DATASET_DIR = (ROOT / \"Dataset\")\n",
    "ARTIFACTS_DIR = (ROOT / \"artifacts\")\n",
    "PROCESSED_DIR = ARTIFACTS_DIR / \"processed\"\n",
    "FIGURES_DIR = ARTIFACTS_DIR / \"figures\"\n",
    "LOGS_DIR = ROOT / \"logs\"\n",
    "for p in [ARTIFACTS_DIR, PROCESSED_DIR, PROCESSED_DIR / \"records\", FIGURES_DIR, LOGS_DIR]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print('ROOT:', ROOT)\n",
    "print('DATASET_DIR:', DATASET_DIR)\n",
    "print('DATASET_DIR exists:', DATASET_DIR.exists())\n",
    "if DATASET_DIR.exists():\n",
    "    subdirs = [d.name for d in DATASET_DIR.iterdir() if d.is_dir()]\n",
    "    print(f'Dataset subdirectories: {subdirs}')\n",
    "print('ARTIFACTS_DIR:', ARTIFACTS_DIR)\n",
    "print('PROCESSED_DIR:', PROCESSED_DIR)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. ENVIRONMENT CHECKS & SETUP\n",
    "Detects hardware, sets deterministic seeds, configures device and mixed precision.\n"
   ],
   "id": "6a883d57986381bf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Environment checks: imports, device detection, seeds, asyncio fix\n",
    "import os, sys, random, json, time, math, asyncio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import Counter, defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "# Windows asyncio policy fix (prevents timeout warnings in nbconvert)\n",
    "if sys.platform == \"win32\":\n",
    "    try:\n",
    "        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())\n",
    "        print(\"[Windows] asyncio policy set to WindowsSelectorEventLoopPolicy\")\n",
    "    except Exception as e:\n",
    "        print(f\"[Warning] Could not set asyncio policy: {e}\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ENVIRONMENT CHECK\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Python: {sys.version.split()[0]}\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"NumPy: {np.__version__}\")\n",
    "print(f\"Pandas: {pd.__version__}\")\n",
    "\n",
    "# Device detection\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"\\nDevice: {DEVICE}\")\n",
    "\n",
    "if DEVICE.type == 'cuda':\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "    gpu_mem_gb = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    print(f\"GPU Memory: {gpu_mem_gb:.2f} GB\")\n",
    "    print(f\"Available GPUs: {torch.cuda.device_count()}\")\n",
    "\n",
    "    # Set batch size based on GPU\n",
    "    BATCH_SIZE = BATCH_SIZE_GPU\n",
    "    USE_AMP = MIXED_PRECISION\n",
    "    print(f\"\\n[GPU Mode] Batch size: {BATCH_SIZE}, Mixed Precision: {USE_AMP}\")\n",
    "\n",
    "    # Optional: enable cudnn benchmark for performance\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.deterministic = False  # Slight speed boost, minor non-determinism\n",
    "else:\n",
    "    BATCH_SIZE = BATCH_SIZE_CPU\n",
    "    USE_AMP = False\n",
    "    print(f\"\\n[CPU Mode] Batch size: {BATCH_SIZE}, Mixed Precision: disabled\")\n",
    "\n",
    "# Set deterministic seeds (use SEED from config or default)\n",
    "if 'SEED' not in globals():\n",
    "    SEED = 42\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if DEVICE.type == 'cuda':\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "print(f\"\\nSeed: {SEED} (deterministic mode enabled)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check disk space (optional sanity check)\n",
    "try:\n",
    "    import shutil\n",
    "    total, used, free = shutil.disk_usage(str(ROOT))\n",
    "    free_gb = free / (1024**3)\n",
    "    print(f\"Free disk space: {free_gb:.2f} GB\")\n",
    "    if free_gb < 50:\n",
    "        print(\"[Warning] Less than 50GB free. Preprocessing may require significant space.\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "print(\"=\" * 60)\n"
   ],
   "id": "2e63890a281f5259"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. CONFIGURATION - USER-TUNABLE HYPERPARAMETERS\n",
    "Edit this cell to configure your training run. All settings have sensible defaults.\n"
   ],
   "id": "94debc5655b14423"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fa1b2ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T06:16:22.771259Z",
     "start_time": "2025-12-02T06:16:22.764018Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH_SIZE 8 EPOCHS 2 AMP False\n"
     ]
    }
   ],
   "source": [
    "# ===== PRODUCTION TRAINING CONFIGURATION =====\n",
    "# Adjust these parameters based on your hardware and dataset size\n",
    "\n",
    "# --- Data preprocessing ---\n",
    "TARGET_FS = 500                           # Target sampling frequency (Hz)\n",
    "TARGET_SAMPLES = 5000                     # Signal length (10s @ 500Hz)\n",
    "ECG_PREPROCESS_LIMIT = 0                  # 0=all data, >0=limit for quick runs (e.g., 5000)\n",
    "\n",
    "# --- Training hyperparameters ---\n",
    "BATCH_SIZE_CPU = 8                        # Batch size when running on CPU\n",
    "BATCH_SIZE_GPU = 64                       # Batch size when GPU available (adjust based on GPU memory)\n",
    "EPOCHS = 20                               # Number of training epochs\n",
    "LR = 1e-3                                 # Initial learning rate\n",
    "WEIGHT_DECAY = 1e-4                       # AdamW weight decay for regularization\n",
    "GRAD_ACCUM_STEPS = 1                      # Gradient accumulation steps (increase if GPU memory limited)\n",
    "CLIP_NORM = 1.0                           # Gradient clipping norm (0 to disable)\n",
    "SCHEDULER_TYPE = 'cosine'                 # 'cosine' or 'step' learning rate schedule\n",
    "EARLY_STOP_PATIENCE = 0                   # Early stopping patience (0 to disable)\n",
    "\n",
    "# --- Performance options ---\n",
    "MIXED_PRECISION = True                    # Enable mixed precision (auto-enabled on CUDA)\n",
    "NUM_WORKERS = 0                           # DataLoader workers (0=main thread, safe for Windows)\n",
    "DRY_RUN = False                           # True: run only 10 steps per epoch for quick validation\n",
    "\n",
    "# --- Paths (auto-detected, override if needed) ---\n",
    "from pathlib import Path\n",
    "import os\n",
    "ROOT = Path(os.environ.get('ECG_ROOT', Path.cwd().parent if Path.cwd().name == 'notebooks' else Path.cwd()))\n",
    "DATASET_DIR = ROOT / \"Dataset\"\n",
    "ARTIFACTS_DIR = ROOT / \"artifacts\"\n",
    "PROCESSED_DIR = ARTIFACTS_DIR / \"processed\"\n",
    "CHECKPOINT_DIR = PROCESSED_DIR / \"checkpoints\"\n",
    "FIGURES_DIR = ARTIFACTS_DIR / \"figures\"\n",
    "LOGS_DIR = ROOT / \"logs\"\n",
    "\n",
    "# --- Label configuration ---\n",
    "LABEL_ORDER = ['MI', 'AF', 'BBB', 'NORM', 'OTHER']\n",
    "LABEL_TO_INT = {label: idx for idx, label in enumerate(LABEL_ORDER)}\n",
    "INT_TO_LABEL = {idx: label for label, idx in LABEL_TO_INT.items()}\n",
    "\n",
    "# --- Seeds for reproducibility ---\n",
    "SEED = int(os.environ.get('ECG_SEED', 42))\n",
    "\n",
    "# Create required directories\n",
    "for directory in [ARTIFACTS_DIR, PROCESSED_DIR, CHECKPOINT_DIR, FIGURES_DIR, LOGS_DIR]:\n",
    "    Path(directory).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"CONFIGURATION LOADED\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Dataset limit: {'ALL DATA' if ECG_PREPROCESS_LIMIT == 0 else f'{ECG_PREPROCESS_LIMIT} samples'}\")\n",
    "print(f\"Epochs: {EPOCHS}, LR: {LR}, Weight Decay: {WEIGHT_DECAY}\")\n",
    "print(f\"Batch size (CPU/GPU): {BATCH_SIZE_CPU}/{BATCH_SIZE_GPU}\")\n",
    "print(f\"Scheduler: {SCHEDULER_TYPE}, Grad Accum: {GRAD_ACCUM_STEPS}, Clip: {CLIP_NORM}\")\n",
    "print(f\"Mixed Precision: {MIXED_PRECISION}, Workers: {NUM_WORKERS}\")\n",
    "print(f\"Dry run mode: {DRY_RUN}\")\n",
    "print(f\"Output dirs: {CHECKPOINT_DIR}, {FIGURES_DIR}\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ff10f19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T06:16:33.062429Z",
     "start_time": "2025-12-02T06:16:31.859203Z"
    }
   },
   "outputs": [],
   "source": [
    "# Utilities: IO, normalization, resample, safe save/load\n",
    "import json, gzip\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from pathlib import Path\n",
    "\n",
    "def zscore_norm(x, eps=1e-6):\n",
    "    x = np.asarray(x, dtype=np.float32)\n",
    "    m = x.mean(axis=-1, keepdims=True)\n",
    "    s = x.std(axis=-1, keepdims=True)\n",
    "    s[s < eps] = 1.0\n",
    "    return (x - m) / s\n",
    "\n",
    "def pad_or_truncate(x, target_len):\n",
    "    x = np.asarray(x, dtype=np.float32)\n",
    "    if x.ndim == 1:\n",
    "        if x.shape[0] >= target_len:\n",
    "            return x[:target_len]\n",
    "        else:\n",
    "            pad = target_len - x.shape[0]\n",
    "            return np.pad(x, (0, pad), mode='constant')\n",
    "    elif x.ndim == 2:\n",
    "        # assume shape (leads, samples)\n",
    "        if x.shape[1] >= target_len:\n",
    "            return x[:, :target_len]\n",
    "        else:\n",
    "            pad = target_len - x.shape[1]\n",
    "            return np.pad(x, ((0,0),(0,pad)), mode='constant')\n",
    "    else:\n",
    "        raise ValueError('Unexpected signal shape')\n",
    "\n",
    "def safe_save_npz(path: Path, signal_array, label:int, metadata=None):\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    if metadata is None:\n",
    "        metadata = {}\n",
    "    np.savez_compressed(path, signal=signal_array.astype(np.float32), label=int(label), metadata=json.dumps(metadata))\n",
    "\n",
    "def load_npz(path:Path):\n",
    "    with np.load(path, allow_pickle=True) as d:\n",
    "        sig = d['signal'].astype(np.float32)\n",
    "        lbl = int(d['label'])\n",
    "        meta = json.loads(d['metadata'].tolist() if hasattr(d['metadata'],'tolist') else d['metadata'])\n",
    "    return sig, lbl, meta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8d351e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T06:16:41.272274Z",
     "start_time": "2025-12-02T06:16:38.856386Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded unified mapping: D:\\ecg-research\\logs\\unified_label_mapping.csv 84556\n",
      "Datasets in mapping: ['ptb-xl', 'CinC2017', 'PTB_Diagnostic', 'Chapman_Shaoxing']\n"
     ]
    }
   ],
   "source": [
    "# Load unified mapping if present; else load candidate, else fallback\n",
    "from collections import Counter\n",
    "UNIFIED_CSV = LOGS_DIR / \"unified_label_mapping.csv\"\n",
    "CANDIDATE_CSV = LOGS_DIR / \"unified_label_mapping.candidate.csv\"\n",
    "\n",
    "mapping_index = {}\n",
    "if UNIFIED_CSV.exists() and UNIFIED_CSV.stat().st_size>0:\n",
    "    df_map = pd.read_csv(UNIFIED_CSV, dtype=str).fillna('')\n",
    "    print('Loaded unified mapping:', UNIFIED_CSV, len(df_map))\n",
    "else:\n",
    "    if CANDIDATE_CSV.exists() and CANDIDATE_CSV.stat().st_size>0:\n",
    "        df_map = pd.read_csv(CANDIDATE_CSV, dtype=str).fillna('')\n",
    "        print('Loaded candidate mapping:', CANDIDATE_CSV, len(df_map))\n",
    "    else:\n",
    "        df_map = pd.DataFrame(columns=['dataset','record_id','mapped_label'])\n",
    "        print('No mapping CSV found; will default to OTHER')\n",
    "\n",
    "# Build mapping index (dataset -> key -> label)\n",
    "for _, row in df_map.iterrows():\n",
    "    ds = str(row.get('dataset','')).strip()\n",
    "    rid = str(row.get('record_id','')).strip().replace('\\\\','/').strip('/')\n",
    "    lab = str(row.get('mapped_label','')).strip().upper()\n",
    "    if not ds or not rid:\n",
    "        continue\n",
    "    mapping_index.setdefault(ds, {})[rid] = lab\n",
    "\n",
    "print('Datasets in mapping:', list(mapping_index.keys())[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da10f658",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T06:16:48.709116Z",
     "start_time": "2025-12-02T06:16:48.702658Z"
    }
   },
   "outputs": [],
   "source": [
    "# label lookup utility used during preprocessing\n",
    "def lookup_mapped_label(dataset_name, record_id):\n",
    "    idx = mapping_index.get(dataset_name, {})\n",
    "    if record_id in idx:\n",
    "        lab = idx[record_id].upper()\n",
    "        return lab if lab in LABEL_TO_INT else 'OTHER'\n",
    "    # try basename\n",
    "    base = record_id.split('/')[-1]\n",
    "    if base in idx:\n",
    "        lab = idx[base].upper()\n",
    "        return lab if lab in LABEL_TO_INT else 'OTHER'\n",
    "    return 'OTHER'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee9f5d5",
   "metadata": {},
   "source": [
    "## Preprocessing (streaming). This cell scans supported datasets and writes per-record .npz files into artifacts/processed/records. It is I/O-heavy and may take hours for full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "388039c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T16:47:32.451428Z",
     "start_time": "2025-12-02T06:16:54.357772Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets found: ['Chapman_Shaoxing', 'CinC2017', 'ptb-xl', 'PTB_Diagnostic']\n",
      "Processing limit (0 means all): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Chapman_Shaoxing: 100%|██████████| 90304/90304 [4:02:02<00:00,  6.22file/s]   \n",
      "Processing CinC2017: 100%|██████████| 17656/17656 [48:34<00:00,  6.06file/s] \n",
      "Processing ptb-xl: 100%|██████████| 87196/87196 [5:33:57<00:00,  4.35file/s]   \n",
      "Processing PTB_Diagnostic: 100%|██████████| 1098/1098 [05:26<00:00,  3.37file/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. processed: 196252 skipped: 2\n",
      "Splits saved. Train: 157001 Val: 19625 Test: 19626\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing: very conservative memory-safe loop\n",
    "import wfdb\n",
    "import scipy.io\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import traceback\n",
    "\n",
    "RECORDS_DIR = PROCESSED_DIR / \"records\"\n",
    "RECORDS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# helper to read recordings (WFDB .hea/.dat or .mat)\n",
    "def read_record_generic(full_path: Path):\n",
    "    # returns (signal (n_leads, n_samples), fs, meta_dict)\n",
    "    try:\n",
    "        if full_path.suffix.lower() == '.mat':\n",
    "            data = scipy.io.loadmat(str(full_path))\n",
    "            # try several common keys\n",
    "            for k in ['val','data','sig','ecg']:\n",
    "                if k in data:\n",
    "                    arr = data[k]\n",
    "                    arr = np.asarray(arr, dtype=np.float32)\n",
    "                    if arr.ndim==2 and arr.shape[0] > arr.shape[1]:\n",
    "                        # ensure shape (leads, samples)\n",
    "                        return arr, int(data.get('fs', TARGET_FS)), {'source':'mat','path':str(full_path)}\n",
    "            # fallback - find first numeric\n",
    "            arr = None\n",
    "            for v in data.values():\n",
    "                if isinstance(v, np.ndarray) and v.ndim==2:\n",
    "                    arr = v.astype(np.float32)\n",
    "                    break\n",
    "            if arr is None:\n",
    "                raise RuntimeError('No 2D array found in mat')\n",
    "            return arr, int(data.get('fs', TARGET_FS)), {'source':'mat','path':str(full_path)}\n",
    "        else:\n",
    "            # WFDB read using record name without .hea\n",
    "            rec_dir = full_path.parent\n",
    "            rec_name = full_path.stem\n",
    "            record = wfdb.rdrecord(str(full_path.with_suffix('')))\n",
    "            sig = np.asarray(record.p_signal.T, dtype=np.float32)  # shape (leads, samples)\n",
    "            fs = int(getattr(record, 'fs', TARGET_FS))\n",
    "            return sig, fs, {'source':'wfdb','path':str(full_path)}\n",
    "    except Exception as e:\n",
    "        # bubble up\n",
    "        raise\n",
    "\n",
    "# iterate datasets (supported minimal set)\n",
    "candidates = []\n",
    "if DATASET_DIR.exists():\n",
    "    for ds in sorted(DATASET_DIR.iterdir()):\n",
    "        if ds.is_dir():\n",
    "            candidates.append(ds)\n",
    "print('Datasets found:', [p.name for p in candidates])\n",
    "\n",
    "# We'll process with a limit if provided\n",
    "LIMIT = int(os.environ.get('ECG_PREPROCESS_LIMIT', 0))\n",
    "print('Processing limit (0 means all):', LIMIT)\n",
    "\n",
    "manifest = []\n",
    "skipped = 0\n",
    "processed = 0\n",
    "\n",
    "# For speed and safety, define file patterns per dataset (common)\n",
    "patterns = {\n",
    "    'ptb-xl': ['**/*.dat','**/*.hea','**/*_hr.mat','**/*_lr.mat'],\n",
    "    'CinC2017': ['**/*.mat','**/*.hea','**/*.atr','training/*.mat'],\n",
    "    'PTB_Diagnostic': ['**/*.dat','**/*.hea'],\n",
    "    'Chapman_Shaoxing': ['**/*.dat','**/*.hea','**/*.mat']\n",
    "}\n",
    "\n",
    "# If wfdb package missing, fallback to synthetic creation\n",
    "if not candidates:\n",
    "    print('No dataset folders – generating synthetic samples for quick smoke tests')\n",
    "    t = np.linspace(0, 10, TARGET_SAMPLES, dtype=np.float32)\n",
    "    for i in range(200):\n",
    "        s = np.sin(2*np.pi*(1+i*0.1)*t).astype(np.float32)\n",
    "        out = RECORDS_DIR / f\"SYNTH_{i:05d}.npz\"\n",
    "        safe_save_npz(out, s, i%len(LABEL_ORDER), {'dataset':'SYNTH'})\n",
    "        manifest.append({'path': f\"records/{out.name}\", 'label': int(i%len(LABEL_ORDER))})\n",
    "    processed = len(manifest)\n",
    "else:\n",
    "    # iterate dataset folders and patterns\n",
    "    for ds in candidates:\n",
    "        ds_name = ds.name\n",
    "        pat_list = patterns.get(ds_name, ['**/*.hea','**/*.mat','**/*.dat'])\n",
    "        files = []\n",
    "        for pat in pat_list:\n",
    "            files.extend(list(ds.rglob(pat)))\n",
    "        # prefer .hea as index entries: convert to unique set\n",
    "        files = sorted(set(files))\n",
    "        if LIMIT and processed >= LIMIT:\n",
    "            break\n",
    "        for fpath in tqdm(files, desc=f\"Processing {ds_name}\", unit='file'):\n",
    "            try:\n",
    "                # simple TRY: read using wfdb or mat loader; if fails, skip\n",
    "                try:\n",
    "                    sig, fs, meta = read_record_generic(fpath)\n",
    "                except Exception:\n",
    "                    # if WFDB read fails try reading .hea by name\n",
    "                    try:\n",
    "                        rec = wfdb.rdrecord(str(fpath.with_suffix('')))\n",
    "                        sig = np.asarray(rec.p_signal.T, dtype=np.float32)\n",
    "                        fs = int(getattr(rec, 'fs', TARGET_FS))\n",
    "                        meta = {'source':'wfdb'}\n",
    "                    except Exception as e:\n",
    "                        skipped += 1\n",
    "                        continue\n",
    "\n",
    "                # resample if needed\n",
    "                if fs != TARGET_FS:\n",
    "                    # resample each lead\n",
    "                    num = int(round(sig.shape[1] * (TARGET_FS / float(fs))))\n",
    "                    sig = signal.resample(sig, num, axis=1).astype(np.float32)\n",
    "                    fs = TARGET_FS\n",
    "\n",
    "                # normalize and pad/truncate\n",
    "                if sig.ndim == 1:\n",
    "                    sig = np.expand_dims(sig, 0)\n",
    "                sig = zscore_norm(sig)\n",
    "                sig = pad_or_truncate(sig, TARGET_SAMPLES)\n",
    "\n",
    "                # build record id relative to dataset root\n",
    "                try:\n",
    "                    rel = fpath.relative_to(DATASET_DIR).as_posix()\n",
    "                except Exception:\n",
    "                    rel = fpath.name\n",
    "                # lookup mapped label\n",
    "                mapped = lookup_mapped_label(ds_name, rel)\n",
    "                label_int = LABEL_TO_INT.get(mapped, LABEL_TO_INT['OTHER'])\n",
    "\n",
    "                out_file = RECORDS_DIR / f\"{ds_name}__{rel.replace('/','__').replace('.','_')}.npz\"\n",
    "                safe_save_npz(out_file, sig, label_int, {'dataset': ds_name, 'src': rel})\n",
    "                manifest.append({'path': f\"records/{out_file.name}\", 'label': label_int})\n",
    "                processed += 1\n",
    "\n",
    "                if LIMIT and processed >= LIMIT:\n",
    "                    break\n",
    "            except Exception as e:\n",
    "                skipped += 1\n",
    "                # write short log entry\n",
    "                with open(LOGS_DIR / \"preprocess_errors.log\", \"a\", encoding=\"utf-8\") as fh:\n",
    "                    fh.write(f\"{fpath} -> {repr(e)}\\n\")\n",
    "                continue\n",
    "\n",
    "print('Done. processed:', processed, 'skipped:', skipped)\n",
    "# persist manifest and splits\n",
    "import json\n",
    "with open(PROCESSED_DIR / \"manifest.jsonl\", \"w\", encoding=\"utf-8\") as fh:\n",
    "    for rec in manifest:\n",
    "        fh.write(json.dumps(rec) + \"\\n\")\n",
    "\n",
    "# build simple stratified splits\n",
    "from sklearn.model_selection import train_test_split\n",
    "paths = [m['path'] for m in manifest]\n",
    "labels = [m['label'] for m in manifest]\n",
    "if paths:\n",
    "    train_p, test_p, y_train, y_test = train_test_split(paths, labels, test_size=0.2, stratify=labels, random_state=SEED)\n",
    "    val_p, test_p, y_val, y_test = train_test_split(test_p, y_test, test_size=0.5, stratify=y_test, random_state=SEED)\n",
    "    splits = {'paths': {'train': train_p, 'val': val_p, 'test': test_p}}\n",
    "    with open(PROCESSED_DIR / \"splits.json\", \"w\", encoding=\"utf-8\") as fh:\n",
    "        json.dump(splits, fh, indent=2)\n",
    "    print('Splits saved. Train:', len(train_p), 'Val:', len(val_p), 'Test:', len(test_p))\n",
    "else:\n",
    "    print('No manifest entries – nothing to split.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0afe8b",
   "metadata": {},
   "source": [
    "## Dataset & DataLoader (lazy loading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92f01117",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T03:24:23.870588Z",
     "start_time": "2025-12-03T03:24:14.019827Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example batch: torch.Size([8, 1, 5000]) torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "# PyTorch Dataset reading .npz files lazily\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class ECGDataset(Dataset):\n",
    "    def __init__(self, entries, base_dir):\n",
    "        self.entries = entries\n",
    "        self.base_dir = Path(base_dir)\n",
    "    def __len__(self):\n",
    "        return len(self.entries)\n",
    "    def __getitem__(self, idx):\n",
    "        p = self.entries[idx]\n",
    "        sig, label, meta = load_npz(self.base_dir / p.split('records/')[-1])\n",
    "        # ensure shape (1, samples)\n",
    "        if sig.ndim == 2:\n",
    "            # use mean across leads for single-lead baseline\n",
    "            sig = sig.mean(axis=0, keepdims=True)\n",
    "        tensor = torch.from_numpy(sig).float()\n",
    "        return tensor, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "# quick loader constructor\n",
    "def build_loaders(limit=None):\n",
    "    import json\n",
    "    with open(PROCESSED_DIR / 'splits.json','r') as fh:\n",
    "        splits = json.load(fh)\n",
    "    train_list = splits['paths']['train']\n",
    "    val_list = splits['paths']['val']\n",
    "    test_list = splits['paths']['test']\n",
    "    if limit:\n",
    "        train_list = train_list[:limit]\n",
    "        val_list = val_list[:int(limit*0.2)]\n",
    "        test_list = test_list[:int(limit*0.2)]\n",
    "    train_ds = ECGDataset(train_list, PROCESSED_DIR / 'records')\n",
    "    val_ds = ECGDataset(val_list, PROCESSED_DIR / 'records')\n",
    "    test_ds = ECGDataset(test_list, PROCESSED_DIR / 'records')\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "    test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "# show example batch if available\n",
    "try:\n",
    "    tr, va, te = build_loaders(limit=16)\n",
    "    xb, yb = next(iter(tr))\n",
    "    print('example batch:', xb.shape, yb.shape)\n",
    "except Exception as e:\n",
    "    print('build_loaders failed:', e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580180f4",
   "metadata": {},
   "source": [
    "## Model (compact 1D ResNet-like). GPU intensive: forward/backward, mixed precision."
   ]
  },
  {
   "cell_type": "code",
   "id": "d43c85b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T03:30:33.045554Z",
     "start_time": "2025-12-03T03:30:32.393582Z"
    }
   },
   "source": [
    "# Simple 1D CNN with residual blocks\n",
    "import torch.nn as nn\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, k=7, s=2):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv1d(in_ch, out_ch, kernel_size=k, stride=s, padding=k//2)\n",
    "        self.bn = nn.BatchNorm1d(out_ch)\n",
    "        self.act = nn.GELU()\n",
    "    def forward(self,x):\n",
    "        return self.act(self.bn(self.conv(x)))\n",
    "\n",
    "class SmallResNet1D(nn.Module):\n",
    "    def __init__(self, in_ch=1, num_classes=len(LABEL_ORDER)):\n",
    "        super().__init__()\n",
    "        self.stem = nn.Sequential(\n",
    "            ConvBlock(in_ch, 16, k=11, s=2),\n",
    "            ConvBlock(16, 32, k=9, s=2),\n",
    "        )\n",
    "        self.res1 = nn.Sequential(\n",
    "            ConvBlock(32, 32, k=7, s=1),\n",
    "            ConvBlock(32, 32, k=5, s=1),\n",
    "        )\n",
    "        self.head = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool1d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(32, num_classes)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x = self.stem(x)\n",
    "        r = self.res1(x)\n",
    "        x = x + r\n",
    "        return self.head(x)\n",
    "\n",
    "model = SmallResNet1D().to(DEVICE)\n",
    "print(model)\n",
    "print('num params:', sum(p.numel() for p in model.parameters() if p.requires_grad))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SmallResNet1D(\n",
      "  (stem): Sequential(\n",
      "    (0): ConvBlock(\n",
      "      (conv): Conv1d(1, 16, kernel_size=(11,), stride=(2,), padding=(5,))\n",
      "      (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): GELU(approximate='none')\n",
      "    )\n",
      "    (1): ConvBlock(\n",
      "      (conv): Conv1d(16, 32, kernel_size=(9,), stride=(2,), padding=(4,))\n",
      "      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): GELU(approximate='none')\n",
      "    )\n",
      "  )\n",
      "  (res1): Sequential(\n",
      "    (0): ConvBlock(\n",
      "      (conv): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): GELU(approximate='none')\n",
      "    )\n",
      "    (1): ConvBlock(\n",
      "      (conv): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): GELU(approximate='none')\n",
      "    )\n",
      "  )\n",
      "  (head): Sequential(\n",
      "    (0): AdaptiveAvgPool1d(output_size=1)\n",
      "    (1): Flatten(start_dim=1, end_dim=-1)\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=32, out_features=5, bias=True)\n",
      "  )\n",
      ")\n",
      "num params: 17573\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "d60d6f66",
   "metadata": {},
   "source": [
    "## 7. PRODUCTION TRAINING LOOP\n",
    "**=== LONG RUN: USER MUST RUN THIS CELL MANUALLY ===**\n",
    "\n",
    "Full-featured training with:\n",
    "- Mixed precision (AMP)\n",
    "- Gradient accumulation & clipping\n",
    "- Cosine/step LR scheduler\n",
    "- Checkpointing & resume\n",
    "- Early stopping (optional)\n",
    "- Per-class metrics logging\n",
    "\n",
    "**Estimated runtime:** ~10-60 min depending on dataset size and hardware\n",
    "**Disk usage:** ~500MB-2GB for checkpoints\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "27af72be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T03:33:25.960507Z",
     "start_time": "2025-12-03T03:33:23.398727Z"
    }
   },
   "source": [
    "# Production training loop with all features\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, StepLR\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, precision_recall_fscore_support\n",
    "import json\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "def worker_init_fn(worker_id):\n",
    "    \"\"\"Ensure reproducible DataLoader workers\"\"\"\n",
    "    np.random.seed(SEED + worker_id)\n",
    "    random.seed(SEED + worker_id)\n",
    "\n",
    "def compute_class_weights(labels):\n",
    "    \"\"\"Compute class weights for imbalanced datasets\"\"\"\n",
    "    from collections import Counter\n",
    "    counts = Counter(labels)\n",
    "    total = sum(counts.values())\n",
    "    weights = {cls: total / (len(counts) * count) for cls, count in counts.items()}\n",
    "    weight_tensor = torch.tensor([weights.get(i, 1.0) for i in range(len(LABEL_ORDER))], dtype=torch.float32)\n",
    "    return weight_tensor\n",
    "\n",
    "def evaluate_detailed(model, loader, device):\n",
    "    \"\"\"Comprehensive evaluation with per-class metrics\"\"\"\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "            if USE_AMP:\n",
    "                with torch.amp.autocast('cuda'):\n",
    "                    logits = model(xb)\n",
    "            else:\n",
    "                logits = model(xb)\n",
    "\n",
    "            probs = torch.softmax(logits, dim=1)\n",
    "            preds = logits.argmax(dim=1)\n",
    "\n",
    "            all_labels.extend(yb.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "    # Compute metrics\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    f1_macro = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    f1_weighted = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "\n",
    "    # Per-class metrics\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(\n",
    "        all_labels, all_preds, average=None, zero_division=0\n",
    "    )\n",
    "\n",
    "    per_class = {}\n",
    "    for idx, label_name in enumerate(LABEL_ORDER):\n",
    "        per_class[label_name] = {\n",
    "            'precision': float(precision[idx]) if idx < len(precision) else 0.0,\n",
    "            'recall': float(recall[idx]) if idx < len(recall) else 0.0,\n",
    "            'f1': float(f1[idx]) if idx < len(f1) else 0.0,\n",
    "            'support': int(support[idx]) if idx < len(support) else 0\n",
    "        }\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    return {\n",
    "        'accuracy': float(acc),\n",
    "        'f1_macro': float(f1_macro),\n",
    "        'f1_weighted': float(f1_weighted),\n",
    "        'per_class': per_class,\n",
    "        'confusion_matrix': cm.tolist(),\n",
    "        'labels': all_labels,\n",
    "        'predictions': all_preds,\n",
    "        'probabilities': all_probs\n",
    "    }\n",
    "\n",
    "def train_production(model, train_loader, val_loader, test_loader=None):\n",
    "    \"\"\"\n",
    "    Production training with all features enabled.\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"PRODUCTION TRAINING START\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Device: {DEVICE}\")\n",
    "    print(f\"Batch size: {BATCH_SIZE}, Epochs: {EPOCHS}\")\n",
    "    print(f\"LR: {LR}, Weight decay: {WEIGHT_DECAY}\")\n",
    "    print(f\"Gradient accumulation: {GRAD_ACCUM_STEPS}, Clip norm: {CLIP_NORM}\")\n",
    "    print(f\"Scheduler: {SCHEDULER_TYPE}, Early stop patience: {EARLY_STOP_PATIENCE}\")\n",
    "    print(f\"Mixed precision: {USE_AMP}\")\n",
    "    print(f\"Dry run: {DRY_RUN}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Setup optimizer and scheduler\n",
    "    optimizer = AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "    if SCHEDULER_TYPE == 'cosine':\n",
    "        scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=LR * 0.01)\n",
    "    else:\n",
    "        scheduler = StepLR(optimizer, step_size=max(1, EPOCHS // 3), gamma=0.1)\n",
    "\n",
    "    # Mixed precision scaler\n",
    "    scaler = torch.amp.GradScaler('cuda', enabled=USE_AMP and DEVICE.type == 'cuda')\n",
    "\n",
    "    # Compute class weights for imbalanced data\n",
    "    all_labels = [item['label'] for item in json.load(open(PROCESSED_DIR / 'splits.json'))['paths']['train']]\n",
    "    # Actually we need to load from manifest - simplified for now\n",
    "    try:\n",
    "        # Try to compute weights from available data\n",
    "        sample_labels = []\n",
    "        for i, (_, y) in enumerate(train_loader):\n",
    "            sample_labels.extend(y.numpy())\n",
    "            if i >= 10:  # Sample first 10 batches\n",
    "                break\n",
    "        class_weights = compute_class_weights(sample_labels)\n",
    "        print(f\"Class weights: {class_weights.tolist()}\")\n",
    "        criterion = nn.CrossEntropyLoss(weight=class_weights.to(DEVICE))\n",
    "    except Exception as e:\n",
    "        print(f\"[Warning] Could not compute class weights: {e}\")\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Training state\n",
    "    start_epoch = 0\n",
    "    best_val_f1 = -1.0\n",
    "    patience_counter = 0\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'val_loss': [],\n",
    "        'val_acc': [],\n",
    "        'val_f1_macro': [],\n",
    "        'val_f1_weighted': [],\n",
    "        'learning_rates': []\n",
    "    }\n",
    "\n",
    "    # Resume from checkpoint if exists\n",
    "    resume_ckpt = CHECKPOINT_DIR / \"last_checkpoint.pth\"\n",
    "    if resume_ckpt.exists():\n",
    "        print(f\"\\n[Resume] Loading checkpoint from {resume_ckpt}\")\n",
    "        try:\n",
    "            ckpt = torch.load(resume_ckpt, map_location=DEVICE)\n",
    "            model.load_state_dict(ckpt['model_state'])\n",
    "            optimizer.load_state_dict(ckpt['optimizer_state'])\n",
    "            scheduler.load_state_dict(ckpt['scheduler_state'])\n",
    "            if 'scaler_state' in ckpt and USE_AMP:\n",
    "                scaler.load_state_dict(ckpt['scaler_state'])\n",
    "            start_epoch = ckpt.get('epoch', 0)\n",
    "            history = ckpt.get('history', history)\n",
    "            best_val_f1 = ckpt.get('best_val_f1', -1.0)\n",
    "            print(f\"[Resume] Continuing from epoch {start_epoch}, best val F1: {best_val_f1:.4f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[Warning] Could not resume from checkpoint: {e}\")\n",
    "            print(\"[Warning] Starting from scratch\")\n",
    "\n",
    "    # Training loop\n",
    "    total_start = time.time()\n",
    "\n",
    "    for epoch in range(start_epoch, EPOCHS):\n",
    "        epoch_start = time.time()\n",
    "        model.train()\n",
    "\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "\n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\", disable=False)\n",
    "\n",
    "        for batch_idx, (xb, yb) in enumerate(pbar):\n",
    "            if DRY_RUN and batch_idx >= 10:\n",
    "                break\n",
    "\n",
    "            xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "\n",
    "            # Forward pass with mixed precision\n",
    "            if USE_AMP:\n",
    "                with torch.amp.autocast('cuda'):\n",
    "                    logits = model(xb)\n",
    "                    loss = criterion(logits, yb) / GRAD_ACCUM_STEPS\n",
    "            else:\n",
    "                logits = model(xb)\n",
    "                loss = criterion(logits, yb) / GRAD_ACCUM_STEPS\n",
    "\n",
    "            # Backward pass\n",
    "            if USE_AMP:\n",
    "                scaler.scale(loss).backward()\n",
    "            else:\n",
    "                loss.backward()\n",
    "\n",
    "            # Gradient accumulation\n",
    "            if (batch_idx + 1) % GRAD_ACCUM_STEPS == 0:\n",
    "                if CLIP_NORM > 0:\n",
    "                    if USE_AMP:\n",
    "                        scaler.unscale_(optimizer)\n",
    "                    nn.utils.clip_grad_norm_(model.parameters(), CLIP_NORM)\n",
    "\n",
    "                if USE_AMP:\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                else:\n",
    "                    optimizer.step()\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            # Statistics\n",
    "            train_loss += loss.item() * GRAD_ACCUM_STEPS\n",
    "            preds = logits.argmax(dim=1)\n",
    "            train_correct += (preds == yb).sum().item()\n",
    "            train_total += yb.size(0)\n",
    "\n",
    "            # Update progress bar\n",
    "            pbar.set_postfix({\n",
    "                'loss': f\"{train_loss / (batch_idx + 1):.4f}\",\n",
    "                'acc': f\"{100.0 * train_correct / train_total:.2f}%\"\n",
    "            })\n",
    "\n",
    "        # Epoch metrics\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        train_acc = train_correct / train_total\n",
    "\n",
    "        # Validation\n",
    "        print(\"\\n[Validation]\")\n",
    "        val_metrics = evaluate_detailed(model, val_loader, DEVICE)\n",
    "\n",
    "        # Update history\n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_acc'].append(val_metrics['accuracy'])\n",
    "        history['val_f1_macro'].append(val_metrics['f1_macro'])\n",
    "        history['val_f1_weighted'].append(val_metrics['f1_weighted'])\n",
    "        history['learning_rates'].append(optimizer.param_groups[0]['lr'])\n",
    "\n",
    "        # Scheduler step\n",
    "        scheduler.step()\n",
    "\n",
    "        epoch_time = time.time() - epoch_start\n",
    "\n",
    "        # Print epoch summary\n",
    "        print(f\"\\nEpoch {epoch+1}/{EPOCHS} - {epoch_time:.1f}s\")\n",
    "        print(f\"  Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "        print(f\"  Val Acc: {val_metrics['accuracy']:.4f}, Val F1 (macro): {val_metrics['f1_macro']:.4f}\")\n",
    "        print(f\"  LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "\n",
    "        # Save checkpoints\n",
    "        checkpoint = {\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state': model.state_dict(),\n",
    "            'optimizer_state': optimizer.state_dict(),\n",
    "            'scheduler_state': scheduler.state_dict(),\n",
    "            'scaler_state': scaler.state_dict() if USE_AMP else None,\n",
    "            'history': history,\n",
    "            'best_val_f1': best_val_f1,\n",
    "            'config': {\n",
    "                'lr': LR,\n",
    "                'batch_size': BATCH_SIZE,\n",
    "                'epochs': EPOCHS,\n",
    "                'seed': SEED\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # Save last checkpoint\n",
    "        torch.save(checkpoint, CHECKPOINT_DIR / \"last_checkpoint.pth\")\n",
    "\n",
    "        # Save best checkpoint\n",
    "        if val_metrics['f1_macro'] > best_val_f1:\n",
    "            best_val_f1 = val_metrics['f1_macro']\n",
    "            torch.save(checkpoint, CHECKPOINT_DIR / \"best_model.pth\")\n",
    "            print(f\"  [Checkpoint] New best model saved! F1: {best_val_f1:.4f}\")\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        # Early stopping\n",
    "        if EARLY_STOP_PATIENCE > 0 and patience_counter >= EARLY_STOP_PATIENCE:\n",
    "            print(f\"\\n[Early Stop] No improvement for {EARLY_STOP_PATIENCE} epochs. Stopping.\")\n",
    "            break\n",
    "\n",
    "        # Save metrics per epoch\n",
    "        epoch_metrics = {\n",
    "            'epoch': epoch + 1,\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'train_loss': avg_train_loss,\n",
    "            'train_acc': train_acc,\n",
    "            'val_metrics': val_metrics,\n",
    "            'lr': optimizer.param_groups[0]['lr']\n",
    "        }\n",
    "\n",
    "        metrics_file = CHECKPOINT_DIR / f\"metrics_epoch_{epoch+1:03d}.json\"\n",
    "        with open(metrics_file, 'w') as f:\n",
    "            json.dump(epoch_metrics, f, indent=2)\n",
    "\n",
    "    # Training complete\n",
    "    total_time = time.time() - total_start\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"TRAINING COMPLETE\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Total time: {total_time / 60:.1f} minutes\")\n",
    "    print(f\"Best validation F1 (macro): {best_val_f1:.4f}\")\n",
    "\n",
    "    # Save final history\n",
    "    with open(CHECKPOINT_DIR / \"training_history.json\", 'w') as f:\n",
    "        json.dump(history, f, indent=2)\n",
    "\n",
    "    # Test set evaluation if available\n",
    "    if test_loader is not None:\n",
    "        print(\"\\n[Test Set Evaluation]\")\n",
    "        test_metrics = evaluate_detailed(model, test_loader, DEVICE)\n",
    "        print(f\"  Test Acc: {test_metrics['accuracy']:.4f}\")\n",
    "        print(f\"  Test F1 (macro): {test_metrics['f1_macro']:.4f}\")\n",
    "        print(f\"  Test F1 (weighted): {test_metrics['f1_weighted']:.4f}\")\n",
    "\n",
    "        # Save test metrics\n",
    "        with open(CHECKPOINT_DIR / \"test_metrics.json\", 'w') as f:\n",
    "            json.dump({\n",
    "                'accuracy': test_metrics['accuracy'],\n",
    "                'f1_macro': test_metrics['f1_macro'],\n",
    "                'f1_weighted': test_metrics['f1_weighted'],\n",
    "                'per_class': test_metrics['per_class'],\n",
    "                'confusion_matrix': test_metrics['confusion_matrix']\n",
    "            }, f, indent=2)\n",
    "\n",
    "    return history, best_val_f1\n"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "823cd39e",
   "metadata": {},
   "source": [
    "## 8. VISUALIZATION & EVALUATION\n",
    "High-quality plots for training curves, confusion matrix, ROC, and PR curves.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "d9fa4ff5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T03:33:56.672831Z",
     "start_time": "2025-12-03T03:33:55.313049Z"
    }
   },
   "source": [
    "# Comprehensive visualization functions\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "def plot_training_curves(history, save_dir=FIGURES_DIR):\n",
    "    \"\"\"Plot training and validation metrics over epochs\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    fig.suptitle('Training Progress', fontsize=16, fontweight='bold')\n",
    "\n",
    "    # Loss\n",
    "    ax = axes[0, 0]\n",
    "    ax.plot(history.get('train_loss', []), label='Train Loss', marker='o', markersize=4)\n",
    "    if 'val_loss' in history:\n",
    "        ax.plot(history.get('val_loss', []), label='Val Loss', marker='s', markersize=4)\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.set_title('Loss Over Time')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # Accuracy\n",
    "    ax = axes[0, 1]\n",
    "    ax.plot(history.get('train_acc', []), label='Train Acc', marker='o', markersize=4)\n",
    "    ax.plot(history.get('val_acc', []), label='Val Acc', marker='s', markersize=4)\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.set_title('Accuracy Over Time')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # F1 Score\n",
    "    ax = axes[1, 0]\n",
    "    if 'val_f1_macro' in history:\n",
    "        ax.plot(history['val_f1_macro'], label='Val F1 (Macro)', marker='o', markersize=4)\n",
    "    if 'val_f1_weighted' in history:\n",
    "        ax.plot(history['val_f1_weighted'], label='Val F1 (Weighted)', marker='s', markersize=4)\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('F1 Score')\n",
    "    ax.set_title('F1 Score Over Time')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # Learning Rate\n",
    "    ax = axes[1, 1]\n",
    "    if 'learning_rates' in history:\n",
    "        ax.plot(history['learning_rates'], marker='o', markersize=4, color='orange')\n",
    "        ax.set_xlabel('Epoch')\n",
    "        ax.set_ylabel('Learning Rate')\n",
    "        ax.set_title('Learning Rate Schedule')\n",
    "        ax.set_yscale('log')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    save_path = save_dir / f\"training_curves_{timestamp}.png\"\n",
    "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"[Saved] {save_path}\")\n",
    "    return save_path\n",
    "\n",
    "def plot_confusion_matrix(cm, labels=LABEL_ORDER, save_dir=FIGURES_DIR, epoch=None):\n",
    "    \"\"\"Plot confusion matrix heatmap\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "    # Normalize for better visualization\n",
    "    cm_norm = cm.astype('float') / cm.sum(axis=1, keepdims=True)\n",
    "\n",
    "    sns.heatmap(cm_norm, annot=True, fmt='.2f', cmap='Blues',\n",
    "                xticklabels=labels, yticklabels=labels, ax=ax,\n",
    "                cbar_kws={'label': 'Normalized Count'})\n",
    "\n",
    "    ax.set_xlabel('Predicted Label', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('True Label', fontsize=12, fontweight='bold')\n",
    "    title = f'Confusion Matrix'\n",
    "    if epoch is not None:\n",
    "        title += f' (Epoch {epoch})'\n",
    "    ax.set_title(title, fontsize=14, fontweight='bold')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    suffix = f\"_epoch{epoch}\" if epoch else \"\"\n",
    "    save_path = save_dir / f\"confusion_matrix{suffix}_{timestamp}.png\"\n",
    "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"[Saved] {save_path}\")\n",
    "    return save_path\n",
    "\n",
    "def plot_per_class_metrics(per_class_metrics, save_dir=FIGURES_DIR):\n",
    "    \"\"\"Plot per-class precision, recall, F1 bar chart\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    labels = list(per_class_metrics.keys())\n",
    "    precision = [per_class_metrics[l]['precision'] for l in labels]\n",
    "    recall = [per_class_metrics[l]['recall'] for l in labels]\n",
    "    f1 = [per_class_metrics[l]['f1'] for l in labels]\n",
    "\n",
    "    x = np.arange(len(labels))\n",
    "    width = 0.25\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    ax.bar(x - width, precision, width, label='Precision', alpha=0.8)\n",
    "    ax.bar(x, recall, width, label='Recall', alpha=0.8)\n",
    "    ax.bar(x + width, f1, width, label='F1 Score', alpha=0.8)\n",
    "\n",
    "    ax.set_xlabel('Class', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Score', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Per-Class Metrics', fontsize=14, fontweight='bold')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    ax.set_ylim([0, 1.05])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    save_path = save_dir / f\"per_class_metrics_{timestamp}.png\"\n",
    "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"[Saved] {save_path}\")\n",
    "    return save_path\n",
    "\n",
    "def plot_roc_curves(labels, predictions, probabilities, save_dir=FIGURES_DIR):\n",
    "    \"\"\"Plot ROC curves for each class (one-vs-rest)\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    # Binarize labels\n",
    "    n_classes = len(LABEL_ORDER)\n",
    "    y_true = label_binarize(labels, classes=list(range(n_classes)))\n",
    "    y_score = np.array(probabilities)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "    colors = plt.cm.Set1(np.linspace(0, 1, n_classes))\n",
    "\n",
    "    for i, (color, label_name) in enumerate(zip(colors, LABEL_ORDER)):\n",
    "        fpr, tpr, _ = roc_curve(y_true[:, i], y_score[:, i])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        ax.plot(fpr, tpr, color=color, lw=2,\n",
    "                label=f'{label_name} (AUC = {roc_auc:.3f})')\n",
    "\n",
    "    ax.plot([0, 1], [0, 1], 'k--', lw=2, label='Random (AUC = 0.500)')\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.set_xlabel('False Positive Rate', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('True Positive Rate', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('ROC Curves (One-vs-Rest)', fontsize=14, fontweight='bold')\n",
    "    ax.legend(loc='lower right', fontsize=9)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    save_path = save_dir / f\"roc_curves_{timestamp}.png\"\n",
    "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"[Saved] {save_path}\")\n",
    "    return save_path\n",
    "\n",
    "def plot_precision_recall_curves(labels, predictions, probabilities, save_dir=FIGURES_DIR):\n",
    "    \"\"\"Plot Precision-Recall curves for each class\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    # Binarize labels\n",
    "    n_classes = len(LABEL_ORDER)\n",
    "    y_true = label_binarize(labels, classes=list(range(n_classes)))\n",
    "    y_score = np.array(probabilities)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "    colors = plt.cm.Set1(np.linspace(0, 1, n_classes))\n",
    "\n",
    "    for i, (color, label_name) in enumerate(zip(colors, LABEL_ORDER)):\n",
    "        precision, recall, _ = precision_recall_curve(y_true[:, i], y_score[:, i])\n",
    "        avg_precision = average_precision_score(y_true[:, i], y_score[:, i])\n",
    "        ax.plot(recall, precision, color=color, lw=2,\n",
    "                label=f'{label_name} (AP = {avg_precision:.3f})')\n",
    "\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.set_xlabel('Recall', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Precision', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Precision-Recall Curves', fontsize=14, fontweight='bold')\n",
    "    ax.legend(loc='lower left', fontsize=9)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    save_path = save_dir / f\"precision_recall_curves_{timestamp}.png\"\n",
    "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"[Saved] {save_path}\")\n",
    "    return save_path\n",
    "\n",
    "def generate_all_plots(history, test_metrics):\n",
    "    \"\"\"Generate all visualization plots\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"GENERATING VISUALIZATIONS\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Training curves\n",
    "    plot_training_curves(history, FIGURES_DIR)\n",
    "\n",
    "    # Confusion matrix\n",
    "    plot_confusion_matrix(np.array(test_metrics['confusion_matrix']), LABEL_ORDER, FIGURES_DIR)\n",
    "\n",
    "    # Per-class metrics\n",
    "    plot_per_class_metrics(test_metrics['per_class'], FIGURES_DIR)\n",
    "\n",
    "    # ROC curves\n",
    "    plot_roc_curves(test_metrics['labels'], test_metrics['predictions'],\n",
    "                   test_metrics['probabilities'], FIGURES_DIR)\n",
    "\n",
    "    # PR curves\n",
    "    plot_precision_recall_curves(test_metrics['labels'], test_metrics['predictions'],\n",
    "                                 test_metrics['probabilities'], FIGURES_DIR)\n",
    "\n",
    "    print(\"=\" * 60)\n"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "1b9bbcbf",
   "metadata": {},
   "source": [
    "## Smoke tests — quick checks to ensure pipeline integrity"
   ]
  },
  {
   "cell_type": "code",
   "id": "09fcd648",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T03:35:14.477381Z",
     "start_time": "2025-12-03T03:35:10.367441Z"
    }
   },
   "source": [
    "# Basic smoke tests: manifest existence, ability to load one record, model forward pass\n",
    "errors = []\n",
    "if not (PROCESSED_DIR / 'manifest.jsonl').exists():\n",
    "    errors.append('manifest.jsonl missing')\n",
    "else:\n",
    "    # try to load first manifest entry\n",
    "    import json\n",
    "    with open(PROCESSED_DIR / 'manifest.jsonl','r',encoding='utf-8') as fh:\n",
    "        first = fh.readline().strip()\n",
    "    if not first:\n",
    "        errors.append('manifest empty')\n",
    "    else:\n",
    "        rec = json.loads(first)\n",
    "        path = PROCESSED_DIR / 'records' / Path(rec['path']).name\n",
    "        try:\n",
    "            sig, lbl, meta = load_npz(path)\n",
    "            print('Loaded sample shape', sig.shape, 'label', lbl)\n",
    "        except Exception as e:\n",
    "            errors.append(f'load_npz failed: {e}')\n",
    "\n",
    "# model forward test\n",
    "try:\n",
    "    m = model.to(DEVICE)\n",
    "    m.eval()\n",
    "    dummy = torch.randn(2,1,TARGET_SAMPLES).to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        out = m(dummy)\n",
    "    print('Model forward ok, out shape', out.shape)\n",
    "except Exception as e:\n",
    "    errors.append(f'model forward failed: {e}')\n",
    "\n",
    "if errors:\n",
    "    print('SMOKE TESTS FOUND ISSUES:')\n",
    "    for e in errors:\n",
    "        print('-', e)\n",
    "else:\n",
    "    print('SMOKE TESTS PASSED')\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded sample shape (12, 5000) label 4\n",
      "Model forward ok, out shape torch.Size([2, 5])\n",
      "SMOKE TESTS PASSED\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "6c584ad1",
   "metadata": {},
   "source": [
    "## 9. PRE-FLIGHT CHECKLIST\n",
    "Run this before training to verify all requirements are met.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Pre-flight checklist\n",
    "def run_preflight_checks():\n",
    "    \"\"\"Verify all prerequisites before training\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"PRE-FLIGHT CHECKLIST\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    checks_passed = []\n",
    "    checks_failed = []\n",
    "\n",
    "    # Check 1: Dataset directory\n",
    "    if DATASET_DIR.exists():\n",
    "        subdirs = [d.name for d in DATASET_DIR.iterdir() if d.is_dir()]\n",
    "        if subdirs:\n",
    "            checks_passed.append(f\"✓ Dataset directory found with {len(subdirs)} subdirectories\")\n",
    "        else:\n",
    "            checks_failed.append(\"✗ Dataset directory exists but is empty\")\n",
    "    else:\n",
    "        checks_failed.append(\"✗ Dataset directory not found\")\n",
    "\n",
    "    # Check 2: Unified mapping CSV\n",
    "    mapping_csv = LOGS_DIR / \"unified_label_mapping.csv\"\n",
    "    if mapping_csv.exists():\n",
    "        df = pd.read_csv(mapping_csv)\n",
    "        checks_passed.append(f\"✓ Unified mapping CSV found ({len(df)} records)\")\n",
    "\n",
    "        # Check mapping coverage\n",
    "        if 'mapped_label' in df.columns:\n",
    "            unmapped = df['mapped_label'].isna().sum() + (df['mapped_label'] == '').sum()\n",
    "            coverage = 100 * (1 - unmapped / len(df))\n",
    "            if coverage > 80:\n",
    "                checks_passed.append(f\"✓ Mapping coverage: {coverage:.1f}%\")\n",
    "            else:\n",
    "                checks_failed.append(f\"✗ Low mapping coverage: {coverage:.1f}% (recommend >80%)\")\n",
    "    else:\n",
    "        checks_failed.append(\"✗ Unified mapping CSV not found\")\n",
    "\n",
    "    # Check 3: Processed records\n",
    "    manifest_file = PROCESSED_DIR / \"manifest.jsonl\"\n",
    "    if manifest_file.exists():\n",
    "        with open(manifest_file, 'r') as f:\n",
    "            num_records = sum(1 for _ in f)\n",
    "        checks_passed.append(f\"✓ Manifest found ({num_records} processed records)\")\n",
    "    else:\n",
    "        checks_failed.append(\"✗ Manifest not found - run preprocessing first\")\n",
    "\n",
    "    # Check 4: Splits\n",
    "    splits_file = PROCESSED_DIR / \"splits.json\"\n",
    "    if splits_file.exists():\n",
    "        with open(splits_file, 'r') as f:\n",
    "            splits = json.load(f)\n",
    "        train_size = len(splits['paths']['train'])\n",
    "        val_size = len(splits['paths']['val'])\n",
    "        test_size = len(splits['paths']['test'])\n",
    "        checks_passed.append(f\"✓ Splits found (train:{train_size}, val:{val_size}, test:{test_size})\")\n",
    "    else:\n",
    "        checks_failed.append(\"✗ Splits not found - run preprocessing first\")\n",
    "\n",
    "    # Check 5: GPU availability\n",
    "    if torch.cuda.is_available():\n",
    "        mem_gb = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "        checks_passed.append(f\"✓ GPU available: {torch.cuda.get_device_name(0)} ({mem_gb:.1f} GB)\")\n",
    "    else:\n",
    "        checks_passed.append(\"⚠ No GPU detected - training will use CPU (slower)\")\n",
    "\n",
    "    # Check 6: Disk space\n",
    "    try:\n",
    "        import shutil\n",
    "        total, used, free = shutil.disk_usage(str(ROOT))\n",
    "        free_gb = free / (1024**3)\n",
    "        if free_gb > 50:\n",
    "            checks_passed.append(f\"✓ Sufficient disk space: {free_gb:.1f} GB free\")\n",
    "        else:\n",
    "            checks_failed.append(f\"✗ Low disk space: {free_gb:.1f} GB free (recommend >50GB)\")\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Print results\n",
    "    for check in checks_passed:\n",
    "        print(check)\n",
    "\n",
    "    for check in checks_failed:\n",
    "        print(check)\n",
    "\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    if checks_failed:\n",
    "        print(\"\\n⚠ WARNINGS DETECTED - Review failed checks before proceeding\")\n",
    "        return False\n",
    "    else:\n",
    "        print(\"\\n✓ ALL CHECKS PASSED - Ready to train!\")\n",
    "        return True\n",
    "\n",
    "# Run checks\n",
    "run_preflight_checks()\n",
    "    # final eval\n",
    "    rep = evaluate(model, te)\n",
    "    print('Test eval:', rep)\n",
    "    # confusion matrix plot\n",
    "    if 'confusion' in rep:\n",
    "        plot_confusion(rep['confusion'])\n",
    "    return rep\n",
    "\n",
    "# Example usage:\n",
    "# run_full(limit=200, do_preprocess=False, do_train=False)\n",
    "print('Orchestrator ready. To run: run_full(limit=500, do_preprocess=False, do_train=True)')\n"
   ],
   "id": "b0d296539247699a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T04:06:07.795486Z",
     "start_time": "2025-12-03T04:05:27.305090Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ===== QUICK SMOKE TRAIN (256 samples) =====\n",
    "# Paste this as a single cell and run it.\n",
    "import os, json, time\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# safety: ensure dirs exist\n",
    "PROCESSED_DIR = Path(PROCESSED_DIR) if 'PROCESSED_DIR' in globals() else Path('artifacts/processed')\n",
    "FIGURES_DIR = PROCESSED_DIR / 'figures'\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FIGURES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# small safety aliases\n",
    "USE_AMP = bool(globals().get('USE_MIXED_PRECISION', False))\n",
    "BATCH_SIZE = int(globals().get('BATCH_SIZE', 8))\n",
    "EPOCHS = int(1)  # single epoch smoke test\n",
    "LIMIT = 256      # number of train samples to use for smoke test\n",
    "\n",
    "print(\"SMOKE RUN CONFIG: LIMIT=\", LIMIT, \"BATCH_SIZE=\", BATCH_SIZE, \"DEVICE=\", globals().get('DEVICE', 'cpu'), \"USE_AMP=\", USE_AMP)\n",
    "\n",
    "# helper to run safely\n",
    "try:\n",
    "    # build loaders using your notebook's build_loaders() function\n",
    "    tr_loader, val_loader, te_loader = build_loaders(limit=LIMIT)\n",
    "    print(\"Loader sizes (train/val/test):\", len(tr_loader.dataset), len(val_loader.dataset), len(te_loader.dataset))\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\"Failed to build loaders — check splits.json and PROCESSED_DIR. Error: \" + str(e))\n",
    "\n",
    "# quick check on first batch shape\n",
    "xb, yb = next(iter(tr_loader))\n",
    "print(\"sample batch shapes:\", xb.shape, yb.shape)\n",
    "\n",
    "# ensure model, train, evaluate functions are present\n",
    "if 'model' not in globals():\n",
    "    raise RuntimeError(\"Model object 'model' not found in notebook. Define it before running this cell.\")\n",
    "\n",
    "# run training (one epoch) and time it\n",
    "start = time.time()\n",
    "history = train(model, tr_loader, val_loader, epochs=EPOCHS, lr=float(globals().get('LR', 1e-3)))\n",
    "elapsed = time.time() - start\n",
    "print(f\"Smoke training finished in {elapsed:.1f}s\")\n",
    "\n",
    "# save history and plot\n",
    "try:\n",
    "    from pathlib import Path\n",
    "    with open(PROCESSED_DIR / \"smoke_training_history.json\",\"w\",encoding=\"utf-8\") as fh:\n",
    "        json.dump(history, fh, indent=2)\n",
    "    plot_history(history, savepath=FIGURES_DIR/'smoke_training_curves.png')\n",
    "except Exception as e:\n",
    "    print(\"Could not save/plot history:\", e)\n",
    "\n",
    "# final quick eval on test split\n",
    "rep = evaluate(model, te_loader)\n",
    "print(\"Test eval:\", rep)\n",
    "if 'confusion' in rep:\n",
    "    try:\n",
    "        plot_confusion(rep['confusion'], savepath=FIGURES_DIR/'smoke_confusion.png')\n",
    "    except Exception as e:\n",
    "        print(\"Could not plot confusion:\", e)\n",
    "\n",
    "print(\"Artifacts (some):\", list(PROCESSED_DIR.glob(\"*\"))[:10])\n",
    "print(\"Figures (some):\", list(FIGURES_DIR.glob(\"*\"))[:10])\n"
   ],
   "id": "cb7f34fb96dabda6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOKE RUN CONFIG: LIMIT= 256 BATCH_SIZE= 8 DEVICE= cpu USE_AMP= False\n",
      "Loader sizes (train/val/test): 256 51 51\n",
      "sample batch shapes: torch.Size([8, 1, 5000]) torch.Size([8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashasvi sharma\\AppData\\Local\\Temp\\ipykernel_1328\\3603453391.py:26: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=USE_AMP)\n",
      "C:\\Users\\yashasvi sharma\\AppData\\Local\\Temp\\ipykernel_1328\\3603453391.py:37: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=USE_AMP):\n",
      "D:\\ecg-research\\.venv1\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:534: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 loss=1.3237 val_f1=1.0000\n",
      "Smoke training finished in 30.8s\n",
      "Saved D:\\ecg-research\\artifacts\\processed\\figures\\smoke_training_curves.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ecg-research\\.venv1\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:534: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test eval: {'acc': 1.0, 'f1_macro': 1.0, 'confusion': [[51]]}\n",
      "Saved D:\\ecg-research\\artifacts\\processed\\figures\\smoke_confusion.png\n",
      "Artifacts (some): [WindowsPath('D:/ecg-research/artifacts/processed/records'), WindowsPath('D:/ecg-research/artifacts/processed/checkpoints'), WindowsPath('D:/ecg-research/artifacts/processed/manifest.jsonl'), WindowsPath('D:/ecg-research/artifacts/processed/progress.json'), WindowsPath('D:/ecg-research/artifacts/processed/splits.json'), WindowsPath('D:/ecg-research/artifacts/processed/label_map.json'), WindowsPath('D:/ecg-research/artifacts/processed/labels.npy'), WindowsPath('D:/ecg-research/artifacts/processed/figures'), WindowsPath('D:/ecg-research/artifacts/processed/checkpoint_ep1.pth'), WindowsPath('D:/ecg-research/artifacts/processed/best_model.pth')]\n",
      "Figures (some): [WindowsPath('D:/ecg-research/artifacts/processed/figures/smoke_training_curves.png'), WindowsPath('D:/ecg-research/artifacts/processed/figures/smoke_confusion.png')]\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Final notes\n",
    "\n",
    "- For a quick smoke run set `ECG_PREPROCESS_LIMIT=5000` in your environment and run the preprocessing cell.\n",
    "- For full production, run headless overnight: `jupyter nbconvert --to notebook --execute notebooks/master_pipeline.ipynb --output logs/preprocess_run.ipynb`\n",
    "- If you want me to generate a variant that uses TFRecords, ONNX export, MLflow logging, or multi-label training — say which and I'll produce it.\n"
   ],
   "id": "75a72a40452ac078"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
