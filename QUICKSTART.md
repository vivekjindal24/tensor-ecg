# ECG Research Pipeline - Quick Start Guide

## âœ… System Status: OPERATIONAL

All components created, tested, and ready for use.

---

## ğŸš€ Quick Commands

### Run Smoke Test (1 minute)
```bash
cd D:\ecg-research
python scripts\run_full_automation.py --mode smoke
```

### Run Full Pipeline (several hours)
```bash
cd D:\ecg-research
python scripts\run_full_automation.py --mode full
```

### Interactive Notebook
```bash
cd D:\ecg-research
jupyter notebook notebooks\master_pipeline.ipynb
```

---

## ğŸ“ Project Structure

```
D:\ecg-research\
â”œâ”€â”€ notebooks\
â”‚   â””â”€â”€ master_pipeline.ipynb          â† Main notebook (complete pipeline)
â”œâ”€â”€ scripts\
â”‚   â”œâ”€â”€ run_full_automation.py         â† Full automation orchestrator
â”‚   â”œâ”€â”€ run_smoke_test.py              â† Quick smoke test
â”‚   â””â”€â”€ create_master_notebook.py      â† Notebook generator (if regeneration needed)
â”œâ”€â”€ Dataset\                            â† Raw datasets (ptb-xl, CinC2017, etc.)
â”œâ”€â”€ artifacts\
â”‚   â”œâ”€â”€ processed\
â”‚   â”‚   â”œâ”€â”€ records\                    â† Preprocessed .npz files (66,861 files)
â”‚   â”‚   â”œâ”€â”€ manifest.jsonl              â† Record index (4,999 entries)
â”‚   â”‚   â”œâ”€â”€ splits.json                 â† Train/val/test splits
â”‚   â”‚   â”œâ”€â”€ label_map.json              â† Label mappings
â”‚   â”‚   â””â”€â”€ labels.npy                  â† Label array
â”‚   â””â”€â”€ figures\                        â† Generated plots
â”œâ”€â”€ logs\
â”‚   â”œâ”€â”€ unified_label_mapping.csv       â† Label mapping (84,556 records)
â”‚   â”œâ”€â”€ preprocess_automation.log       â† Detailed execution log
â”‚   â””â”€â”€ preprocess_report.txt           â† Summary report
â””â”€â”€ requirements.txt                    â† Python dependencies

```

---

## ğŸ“Š Current Data Status

- **Total mapped records**: 84,556
- **Preprocessed records**: 4,999 (66,861 .npz files on disk)
- **Label distribution**:
  - NORM: 19,286
  - MI: 3,941
  - AF: 2,771
  - BBB: 2,580
  - Unmapped (â†’OTHER): 55,978

---

## ğŸ”§ Configuration

Edit these environment variables before running:

```bash
# Limit records for testing (0 = process all)
set ECG_PREPROCESS_LIMIT=500

# Training epochs
set ECG_EPOCHS=5

# Batch size
set ECG_BATCH_SIZE=32

# Random seed
set ECG_SEED=42
```

---

## ğŸ“ Notebook Sections

The master notebook has these executable cells:

1. **Environment Setup** - Imports, paths, device check
2. **Config** - Hyperparameters (500Hz, 5000 samples, 5 labels)
3. **Utilities** - Normalization, resampling, I/O helpers
4. **Mapping Loader** - Load unified label CSV
5. **Preprocessing** - Stream datasets, save .npz records
6. **Dataset & DataLoader** - Lazy PyTorch dataset
7. **Model** - 1D ResNet-like CNN
8. **Training** - Mixed precision, checkpoints, metrics
9. **Evaluation** - Confusion matrix, plots
10. **Smoke Tests** - Verification
11. **Orchestrator** - Run full pipeline

---

## ğŸ¯ Common Tasks

### Regenerate Notebook
```bash
python create_master_notebook.py
```

### Process More Data
Remove or increase limit, then run:
```bash
set ECG_PREPROCESS_LIMIT=0
python scripts\run_full_automation.py --mode full
```

### Check Logs
```bash
type logs\preprocess_automation.log
type logs\preprocess_report.txt
```

### View Sample Unmapped Records
```bash
type logs\unmapped_sample.csv
```

---

## âš™ï¸ System Info

- **Python**: 3.11.0
- **Virtual Env**: `.venv1`
- **GPU**: None (CPU mode)
- **Free Space**: 792.7 GB
- **OS**: Windows

---

## ğŸ› Troubleshooting

### Issue: Out of memory
**Solution**: Reduce batch size
```bash
set ECG_BATCH_SIZE=4
```

### Issue: Preprocessing too slow
**Solution**: Run with limit first
```bash
set ECG_PREPROCESS_LIMIT=1000
```

### Issue: WFDB read errors
**Solution**: Check logs for patterns
```bash
type logs\preprocess_errors.log
```

### Issue: Missing packages
**Solution**: Reinstall requirements
```bash
pip install -r requirements.txt
```

---

## ğŸ“ˆ Next Steps

1. **Review mapping**: Check `logs/unmapped_sample.csv` to improve label coverage
2. **Run full preprocessing**: Process all 150K+ records
3. **Train model**: Execute training cells in notebook
4. **Evaluate**: Generate confusion matrix and metrics
5. **Export model**: Save checkpoint for inference

---

## ğŸ“š Documentation

- `COMPLETE_SETUP_SUMMARY.md` - Detailed setup report
- `README.md` - Project overview
- `logs/preprocess_report.txt` - Latest run summary

---

## âœ¨ Features

âœ… Idempotent & resumable  
âœ… Memory-safe streaming  
âœ… Multi-format support (WFDB, .mat)  
âœ… GPU-ready with mixed precision  
âœ… Comprehensive logging  
âœ… Smoke tests included  
âœ… Production-ready  

---

**Last Validated**: 2025-12-02 10:52:53  
**Status**: All smoke tests passed âœ…

